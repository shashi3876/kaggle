{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj0O63RU53jX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "THis notebook contains he final notebook submission to the Kaggle competion predcit Calories challenge. I will start by first havoing code to the best possible solution based on the public leaderboard) and then explore other options. EDA and other stuff have been removed from this notebook for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vDPkI88a0LAu"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zFS_dZcX0PWt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6tkK3r9Bcxu"
   },
   "source": [
    "# Use of CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPvK2LUpBs9M"
   },
   "outputs": [],
   "source": [
    "# Define columns to exclude from features\n",
    "exclude_cols = ['id', 'Calories']\n",
    "target_col = 'Calories'\n",
    "\n",
    "# Split features and target from train\n",
    "X_train = train.drop(columns=exclude_cols)\n",
    "y_train = train[target_col]\n",
    "\n",
    "# Prepare test set (same feature columns)\n",
    "X_test = test.drop(columns=['id'])\n",
    "\n",
    "# Identify categorical features (assumes object types are categorical)\n",
    "categorical_features = ['Sex']\n",
    "\n",
    "# Optional: split validation set from train (for early stopping)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Pools\n",
    "train_pool = Pool(X_tr, y_tr, cat_features=categorical_features)\n",
    "val_pool = Pool(X_val, y_val, cat_features=categorical_features)\n",
    "test_pool = Pool(X_test, cat_features=categorical_features)\n",
    "\n",
    "# Train the model\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=10,\n",
    "    random_strength=5,\n",
    "    l2_leaf_reg=7,\n",
    "    bootstrap_type='Bernoulli',\n",
    "    grow_policy='SymmetricTree',\n",
    "    eval_metric='RMSE',\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# Predict on test set\n",
    "test_preds = model.predict(test_pool)\n",
    "\n",
    "# Add predictions to test dataframe\n",
    "test['Calories'] = test_preds\n",
    "\n",
    "# Optional: preview results\n",
    "print(test[['id','Calories']].head())\n",
    "test[['id','Calories']].to_csv('catboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bin 'Duration' into quantile-based categories (e.g., 5 groups)\n",
    "X_train = train.drop(columns=exclude_cols)\n",
    "y_train = train[target_col]\n",
    "\n",
    "# Add Duration binning for stratification\n",
    "duration_bins = pd.qcut(train['Duration'], q=10, labels=False)  # or use pd.cut for fixed bins\n",
    "\n",
    "# Initialize StratifiedKFold using duration bins\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "\n",
    "# Proceed with the same logic â€” just replace KFold with StratifiedKFold\n",
    "for fold, (idx_train, idx_valid) in enumerate(cv.split(X_train, duration_bins)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[idx_train], X_train.iloc[idx_valid]\n",
    "    y_tr, y_val = np.log1p(y_train.iloc[idx_train]), np.log1p(y_train.iloc[idx_valid])\n",
    "    \n",
    "    # CatBoost Pools\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=categorical_features)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_features)\n",
    "    test_pool = Pool(X_test, cat_features=categorical_features)\n",
    "    \n",
    "    # Train and predict as before...\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        random_strength=5,\n",
    "        l2_leaf_reg=7,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        grow_policy='SymmetricTree',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    test_preds += np.expm1(model.predict(test_pool))\n",
    "\n",
    "test_preds /= cv.get_n_splits()\n",
    "test['Calories'] = test_preds\n",
    "test[['id','Calories']].to_csv('catboost_5_fold_str.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "categorical_cols = ['Sex']\n",
    "\n",
    "# Discretize 'duration' into 5 bins for stratification\n",
    "duration_bins = pd.qcut(X['Duration'], q=5, labels=False, duplicates='drop')\n",
    "\n",
    "# Use StratifiedKFold for stratified splitting based on duration bins\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "y_pred = np.zeros(len(test))\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)  # log(1 + y) for RMSLE-friendly training\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, duration_bins):\n",
    "    X_train, y_train = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target Encoding for categorical column\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',  # L2 loss\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "\n",
    "# Average predictions over folds\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# Create submission file\n",
    "pred_xgb = y_pred\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': pred_xgb})\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENsemble the two best cases (In log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('submission_xgb (1).csv')\n",
    "data2=pd.read_csv('catboost_5_fold_str (1).csv')\n",
    "\n",
    "data = data1.merge(data2, on='id', suffixes=('_xgb', '_cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 1. Simple average of the two predictions\n",
    "data['Calories_avg'] = (data['Calories_xgb'] + data['Calories_cat']) / 2\n",
    "\n",
    "# 2. Log-scale average (RMSLE-style averaging)\n",
    "data['Calories_log_avg'] = np.expm1(\n",
    "    (np.log1p(data['Calories_xgb']) + np.log1p(data['Calories_cat'])) / 2\n",
    ")\n",
    "\n",
    "print(data[['id', 'Calories_xgb', 'Calories_cat', 'Calories_avg', 'Calories_log_avg']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simple average with 'Calories' as the second column\n",
    "data[['id', 'Calories_avg']].rename(columns={'Calories_avg': 'Calories'}).to_csv('submission_reg_avg.csv', index=False)\n",
    "\n",
    "# Save log-scale average with 'Calories' as the second column\n",
    "data[['id', 'Calories_log_avg']].rename(columns={'Calories_log_avg': 'Calories'}).to_csv('submission_log_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fresh with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain['Duration_2'] = train['Duration']\\ntest['Duration_2'] = test['Duration']\\n\\ntrain['Age_2'] = train['Age']\\ntest['Age_2'] = test['Age']\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n",
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)\n",
    "\n",
    "# Squares of features\n",
    "train['dur_2']=train['Duration']*train['Duration']\n",
    "test['dur_2']=test['Duration']*test['Duration']\n",
    "\n",
    "train['hr_2']=train['Heart_Rate']*train['Heart_Rate']\n",
    "test['hr_2']=test['Heart_Rate']*test['Heart_Rate']\n",
    "\n",
    "train['height_2']=train['Height']*train['Height']\n",
    "test['height_2']=test['Height']*test['Height']\n",
    "\n",
    "train['weight_2']=train['Weight']*train['Weight']\n",
    "test['weight_2']=test['Weight']*test['Weight']\n",
    "\n",
    "# Square root of Duration\n",
    "train['dur_sqrt'] = train['Duration'] ** 0.5\n",
    "test['dur_sqrt'] = test['Duration'] ** 0.5\n",
    "\n",
    "train['hr_sqrt'] = train['Heart_Rate'] ** 0.5\n",
    "test['hr_sqrt'] = test['Heart_Rate'] ** 0.5\n",
    "\n",
    "train['weight_sqrt'] = train['Weight'] ** 0.5\n",
    "test['weight_sqrt'] = test['Weight'] ** 0.5\n",
    "\n",
    "train['height_sqrt'] = train['Height'] ** 0.5\n",
    "test['height_sqrt'] = test['Height'] ** 0.5\n",
    "\n",
    "train['Intensity'] = train['Heart_Rate'] / train['Duration']\n",
    "test['Intensity'] = test['Heart_Rate'] / test['Duration']\n",
    "\n",
    "# Create binary indicators\n",
    "train['is_male'] = (train['Sex'].str.lower() == 'male').astype(int)\n",
    "train['is_female'] = (train['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "test['is_male'] = (test['Sex'].str.lower() == 'male').astype(int)\n",
    "test['is_female'] = (test['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "# Numerical columns to interact with sex\n",
    "num_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height', 'Body_Temp','bmi','Intensity','dur_body_heart']\n",
    "\n",
    "# Create interaction features\n",
    "for col in num_cols:\n",
    "    train[f'{col}_Male'] = train[col] * train['is_male']\n",
    "    train[f'{col}_Female'] = train[col] * train['is_female']\n",
    "\n",
    "    test[f'{col}_Male'] = test[col] * test['is_male']\n",
    "    test[f'{col}_Female'] = test[col] * test['is_female']\n",
    "\n",
    "\n",
    "for col in ['Weight', 'Height', 'Duration', 'Heart_Rate', 'Body_Temp']:\n",
    "    train[f'{col}_log'] = np.log1p(train[col])\n",
    "    test[f'{col}_log'] = np.log1p(test[col])\n",
    "\n",
    "train['Weight_Height_ratio'] = train['Weight'] / train['Height']\n",
    "test['Weight_Height_ratio'] = test['Weight'] / test['Height']\n",
    "\n",
    "train['HeartRate_BodyTemp_ratio'] = train['Heart_Rate'] / train['Body_Temp']\n",
    "test['HeartRate_BodyTemp_ratio'] = test['Heart_Rate'] / test['Body_Temp']\n",
    "\n",
    "\n",
    "train['effort_per_kg'] = train['Duration'] * train['Heart_Rate'] / train['Weight']\n",
    "test['effort_per_kg'] = test['Duration'] * test['Heart_Rate'] / test['Weight']\n",
    "\n",
    "\n",
    "train['Age_HeartRate'] = train['Age'] * train['Heart_Rate']\n",
    "test['Age_HeartRate'] = test['Age'] * test['Heart_Rate']\n",
    "\n",
    "train['Temp_Height'] = train['Body_Temp'] * train['Height']\n",
    "test['Temp_Height'] = test['Body_Temp'] * test['Height']\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "poly_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height']\n",
    "for col1, col2 in combinations(poly_cols, 2):\n",
    "    train[f'{col1}_x_{col2}'] = train[col1] * train[col2]\n",
    "    test[f'{col1}_x_{col2}'] = test[col1] * test[col2]\n",
    "'''\n",
    "train['Duration_2'] = train['Duration']\n",
    "test['Duration_2'] = test['Duration']\n",
    "\n",
    "train['Age_2'] = train['Age']\n",
    "test['Age_2'] = test['Age']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex']\n",
    "\n",
    "categorical_cols = ['Sex']\n",
    "\n",
    "# Discretize 'duration' into 5 bins for stratification\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Use StratifiedKFold for stratified splitting based on duration bins\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "y_pred = np.zeros(len(test))\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)  # log(1 + y) for RMSLE-friendly training\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, duration_bins):\n",
    "    X_train, y_train = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target Encoding for categorical column\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',  # L2 loss\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "\n",
    "# Average predictions over folds\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# Create submission file\n",
    "pred_xgb = y_pred\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': pred_xgb})\n",
    "submission_xgb.to_csv('submission_xgb_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex','Duration','Age']\n",
    "\n",
    "# Stratification based on binned Duration\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Initialize predictions\n",
    "y_pred = np.zeros(len(test))\n",
    "oof_preds = np.zeros(len(train))  # To store OOF predictions\n",
    "\n",
    "for idx_fold, (idx_train, idx_valid) in enumerate(cv.split(X, duration_bins)):\n",
    "    print(f\"\\nFold {idx_fold + 1}\")\n",
    "    \n",
    "    X_train, y_train_fold = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid_fold = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target encoding\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train_fold)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    # Model\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_fold,\n",
    "        eval_set=[(X_valid, y_valid_fold)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Predict on test and validation sets\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "    oof_preds[idx_valid] = np.expm1(model.predict(X_valid))\n",
    "\n",
    "# Final test prediction (average)\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# OOF RMSLE\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(train['Calories']), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "# Submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': y_pred})\n",
    "submission_xgb.to_csv('submission_xgb_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF RMSLE: 0.05991 => with ratio features\n",
    "OOF RMSLE: 0.05993 => with ratio features + efficiency\n",
    "OOF RMSLE: 0.05988 => with ratio features + efficiency + interation\n",
    "OOF RMSLE: 0.05985 => with ratio features + efficiency + interation + pairwise polynomial\n",
    "OOF RMSLE: 0.05994 => with ratio features +            + interation + pairwise polynomial\n",
    "\n",
    "\n",
    "OOF RMSLE: 0.05983 => with ratio features +  effciency + interation + pairwise polynomial with Duration as a cxategory\n",
    "OOF RMSLE: 0.05983 => with ratio features +  effciency + interation + pairwise polynomial with Duration and Age as a cxategory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex','Duration','Age']\n",
    "categorical_cols = ['Sex','Duration']#,'Age']\n",
    "# Stratification based on binned Duration\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Initialize predictions\n",
    "y_pred = np.zeros(len(test))\n",
    "oof_preds = np.zeros(len(train))  # To store OOF predictions\n",
    "\n",
    "for idx_fold, (idx_train, idx_valid) in enumerate(cv.split(X, duration_bins)):\n",
    "    print(f\"\\nFold {idx_fold + 1}\")\n",
    "    \n",
    "    X_train, y_train_fold = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid_fold = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train_fold)\n",
    "    X_valid[categorical_cols] = encoder.transform(X_valid[categorical_cols])\n",
    "    X_test[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Model\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_fold,\n",
    "        eval_set=[(X_valid, y_valid_fold)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Predict on test and validation sets\n",
    "    y_pred += model.predict(X_test)\n",
    "    oof_preds[idx_valid] = np.expm1(model.predict(X_valid))\n",
    "\n",
    "# Final test prediction (average)\n",
    "y_pred = np.expm1(y_pred / cv.get_n_splits()) \n",
    "\n",
    "# OOF RMSLE\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(train['Calories']), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "# Submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': y_pred})\n",
    "submission_xgb.to_csv('submission_xgb_category.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "0:\tlearn: 0.9365528\ttest: 0.9353485\tbest: 0.9353485 (0)\ttotal: 117ms\tremaining: 3m 52s\n",
      "100:\tlearn: 0.0877443\ttest: 0.0879699\tbest: 0.0879699 (100)\ttotal: 5.39s\tremaining: 1m 41s\n",
      "200:\tlearn: 0.0619111\ttest: 0.0629707\tbest: 0.0629707 (200)\ttotal: 10.8s\tremaining: 1m 36s\n",
      "300:\tlearn: 0.0604706\ttest: 0.0619172\tbest: 0.0619172 (300)\ttotal: 16.1s\tremaining: 1m 30s\n",
      "400:\tlearn: 0.0598075\ttest: 0.0615256\tbest: 0.0615256 (400)\ttotal: 22.3s\tremaining: 1m 29s\n",
      "500:\tlearn: 0.0592577\ttest: 0.0612432\tbest: 0.0612432 (500)\ttotal: 27.7s\tremaining: 1m 22s\n",
      "600:\tlearn: 0.0587654\ttest: 0.0610287\tbest: 0.0610287 (600)\ttotal: 33.8s\tremaining: 1m 18s\n",
      "700:\tlearn: 0.0583421\ttest: 0.0608917\tbest: 0.0608917 (700)\ttotal: 39.5s\tremaining: 1m 13s\n",
      "800:\tlearn: 0.0579884\ttest: 0.0607977\tbest: 0.0607977 (800)\ttotal: 45.4s\tremaining: 1m 7s\n",
      "900:\tlearn: 0.0576507\ttest: 0.0607440\tbest: 0.0607440 (900)\ttotal: 52.9s\tremaining: 1m 4s\n",
      "1000:\tlearn: 0.0573608\ttest: 0.0606797\tbest: 0.0606794 (999)\ttotal: 58.3s\tremaining: 58.2s\n",
      "1100:\tlearn: 0.0570583\ttest: 0.0606320\tbest: 0.0606305 (1092)\ttotal: 1m 3s\tremaining: 52.2s\n",
      "1200:\tlearn: 0.0567730\ttest: 0.0605789\tbest: 0.0605789 (1200)\ttotal: 1m 9s\tremaining: 46.2s\n",
      "1300:\tlearn: 0.0564943\ttest: 0.0605387\tbest: 0.0605385 (1299)\ttotal: 1m 14s\tremaining: 40.1s\n",
      "1400:\tlearn: 0.0562443\ttest: 0.0604983\tbest: 0.0604981 (1399)\ttotal: 1m 19s\tremaining: 34.1s\n",
      "1500:\tlearn: 0.0559998\ttest: 0.0604623\tbest: 0.0604620 (1499)\ttotal: 1m 25s\tremaining: 28.3s\n",
      "1600:\tlearn: 0.0557701\ttest: 0.0604399\tbest: 0.0604392 (1598)\ttotal: 1m 30s\tremaining: 22.5s\n",
      "1700:\tlearn: 0.0555554\ttest: 0.0604267\tbest: 0.0604250 (1696)\ttotal: 1m 35s\tremaining: 16.8s\n",
      "1800:\tlearn: 0.0553409\ttest: 0.0604110\tbest: 0.0604097 (1796)\ttotal: 1m 40s\tremaining: 11.1s\n",
      "1900:\tlearn: 0.0551252\ttest: 0.0603979\tbest: 0.0603979 (1900)\ttotal: 1m 46s\tremaining: 5.54s\n",
      "1999:\tlearn: 0.0549224\ttest: 0.0603855\tbest: 0.0603855 (1999)\ttotal: 1m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06038550337\n",
      "bestIteration = 1999\n",
      "\n",
      "\n",
      "Fold 2\n",
      "0:\tlearn: 0.9362883\ttest: 0.9368525\tbest: 0.9368525 (0)\ttotal: 98.9ms\tremaining: 3m 17s\n",
      "100:\tlearn: 0.0875602\ttest: 0.0866788\tbest: 0.0866788 (100)\ttotal: 5.13s\tremaining: 1m 36s\n",
      "200:\tlearn: 0.0621715\ttest: 0.0613297\tbest: 0.0613297 (200)\ttotal: 10.3s\tremaining: 1m 32s\n",
      "300:\tlearn: 0.0607497\ttest: 0.0602542\tbest: 0.0602542 (300)\ttotal: 15.9s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.0600576\ttest: 0.0598258\tbest: 0.0598258 (400)\ttotal: 21.1s\tremaining: 1m 24s\n",
      "500:\tlearn: 0.0594793\ttest: 0.0595533\tbest: 0.0595533 (500)\ttotal: 26.3s\tremaining: 1m 18s\n",
      "600:\tlearn: 0.0589835\ttest: 0.0593781\tbest: 0.0593781 (600)\ttotal: 31.5s\tremaining: 1m 13s\n",
      "700:\tlearn: 0.0585533\ttest: 0.0592465\tbest: 0.0592465 (699)\ttotal: 36.7s\tremaining: 1m 8s\n",
      "800:\tlearn: 0.0581922\ttest: 0.0591714\tbest: 0.0591712 (799)\ttotal: 41.9s\tremaining: 1m 2s\n",
      "900:\tlearn: 0.0578627\ttest: 0.0590860\tbest: 0.0590860 (900)\ttotal: 47.2s\tremaining: 57.6s\n",
      "1000:\tlearn: 0.0575587\ttest: 0.0590274\tbest: 0.0590274 (1000)\ttotal: 52.5s\tremaining: 52.4s\n",
      "1100:\tlearn: 0.0572774\ttest: 0.0589746\tbest: 0.0589746 (1100)\ttotal: 57.6s\tremaining: 47.1s\n",
      "1200:\tlearn: 0.0570040\ttest: 0.0589303\tbest: 0.0589300 (1199)\ttotal: 1m 2s\tremaining: 41.9s\n",
      "1300:\tlearn: 0.0567402\ttest: 0.0588905\tbest: 0.0588905 (1300)\ttotal: 1m 8s\tremaining: 36.6s\n",
      "1400:\tlearn: 0.0564968\ttest: 0.0588571\tbest: 0.0588571 (1400)\ttotal: 1m 13s\tremaining: 31.4s\n",
      "1500:\tlearn: 0.0562545\ttest: 0.0588443\tbest: 0.0588440 (1487)\ttotal: 1m 18s\tremaining: 26.2s\n",
      "1600:\tlearn: 0.0560245\ttest: 0.0588072\tbest: 0.0588072 (1600)\ttotal: 1m 24s\tremaining: 20.9s\n",
      "1700:\tlearn: 0.0557804\ttest: 0.0587875\tbest: 0.0587875 (1700)\ttotal: 1m 29s\tremaining: 15.7s\n",
      "1800:\tlearn: 0.0555709\ttest: 0.0587681\tbest: 0.0587681 (1800)\ttotal: 1m 34s\tremaining: 10.4s\n",
      "1900:\tlearn: 0.0553463\ttest: 0.0587484\tbest: 0.0587484 (1900)\ttotal: 1m 39s\tremaining: 5.2s\n",
      "1999:\tlearn: 0.0551493\ttest: 0.0587351\tbest: 0.0587351 (1999)\ttotal: 1m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.05873505259\n",
      "bestIteration = 1999\n",
      "\n",
      "\n",
      "Fold 3\n",
      "0:\tlearn: 0.9362890\ttest: 0.9352944\tbest: 0.9352944 (0)\ttotal: 64.5ms\tremaining: 2m 8s\n",
      "100:\tlearn: 0.0876772\ttest: 0.0882432\tbest: 0.0882432 (100)\ttotal: 5.15s\tremaining: 1m 36s\n",
      "200:\tlearn: 0.0618797\ttest: 0.0634974\tbest: 0.0634974 (200)\ttotal: 10.3s\tremaining: 1m 32s\n",
      "300:\tlearn: 0.0605226\ttest: 0.0623844\tbest: 0.0623844 (300)\ttotal: 16.2s\tremaining: 1m 31s\n",
      "400:\tlearn: 0.0598587\ttest: 0.0618948\tbest: 0.0618948 (400)\ttotal: 21.4s\tremaining: 1m 25s\n",
      "500:\tlearn: 0.0592939\ttest: 0.0615478\tbest: 0.0615478 (500)\ttotal: 26.6s\tremaining: 1m 19s\n",
      "600:\tlearn: 0.0587773\ttest: 0.0613214\tbest: 0.0613214 (600)\ttotal: 32.1s\tremaining: 1m 14s\n",
      "700:\tlearn: 0.0583440\ttest: 0.0611544\tbest: 0.0611544 (700)\ttotal: 37.3s\tremaining: 1m 9s\n",
      "800:\tlearn: 0.0579825\ttest: 0.0610335\tbest: 0.0610335 (800)\ttotal: 42.5s\tremaining: 1m 3s\n",
      "900:\tlearn: 0.0576728\ttest: 0.0609539\tbest: 0.0609539 (900)\ttotal: 48s\tremaining: 58.5s\n",
      "1000:\tlearn: 0.0573778\ttest: 0.0608832\tbest: 0.0608832 (1000)\ttotal: 53.1s\tremaining: 53s\n",
      "1100:\tlearn: 0.0571091\ttest: 0.0608175\tbest: 0.0608175 (1100)\ttotal: 58.3s\tremaining: 47.6s\n",
      "1200:\tlearn: 0.0568422\ttest: 0.0607680\tbest: 0.0607667 (1192)\ttotal: 1m 3s\tremaining: 42.2s\n",
      "1300:\tlearn: 0.0565787\ttest: 0.0607240\tbest: 0.0607234 (1296)\ttotal: 1m 8s\tremaining: 36.9s\n",
      "1400:\tlearn: 0.0563250\ttest: 0.0606944\tbest: 0.0606941 (1398)\ttotal: 1m 13s\tremaining: 31.5s\n",
      "1500:\tlearn: 0.0560679\ttest: 0.0606674\tbest: 0.0606672 (1499)\ttotal: 1m 18s\tremaining: 26.2s\n",
      "1600:\tlearn: 0.0558419\ttest: 0.0606432\tbest: 0.0606432 (1600)\ttotal: 1m 24s\tremaining: 21s\n",
      "1700:\tlearn: 0.0556264\ttest: 0.0606109\tbest: 0.0606107 (1698)\ttotal: 1m 29s\tremaining: 15.7s\n",
      "1800:\tlearn: 0.0553979\ttest: 0.0605776\tbest: 0.0605774 (1799)\ttotal: 1m 34s\tremaining: 10.4s\n",
      "1900:\tlearn: 0.0551967\ttest: 0.0605562\tbest: 0.0605552 (1896)\ttotal: 1m 39s\tremaining: 5.19s\n",
      "1999:\tlearn: 0.0549941\ttest: 0.0605487\tbest: 0.0605481 (1997)\ttotal: 1m 44s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.0605481097\n",
      "bestIteration = 1997\n",
      "\n",
      "Shrink model to first 1998 iterations.\n",
      "\n",
      "Fold 4\n",
      "0:\tlearn: 0.9359778\ttest: 0.9370155\tbest: 0.9370155 (0)\ttotal: 49ms\tremaining: 1m 37s\n",
      "100:\tlearn: 0.0874505\ttest: 0.0880126\tbest: 0.0880126 (100)\ttotal: 5.04s\tremaining: 1m 34s\n",
      "200:\tlearn: 0.0620785\ttest: 0.0626227\tbest: 0.0626227 (200)\ttotal: 10.2s\tremaining: 1m 30s\n",
      "300:\tlearn: 0.0605931\ttest: 0.0613680\tbest: 0.0613680 (300)\ttotal: 15.4s\tremaining: 1m 26s\n",
      "400:\tlearn: 0.0598751\ttest: 0.0608407\tbest: 0.0608407 (400)\ttotal: 20.6s\tremaining: 1m 21s\n",
      "500:\tlearn: 0.0592901\ttest: 0.0605082\tbest: 0.0605082 (500)\ttotal: 25.8s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.0587779\ttest: 0.0603013\tbest: 0.0603013 (600)\ttotal: 31s\tremaining: 1m 12s\n",
      "700:\tlearn: 0.0583622\ttest: 0.0601568\tbest: 0.0601568 (700)\ttotal: 36.2s\tremaining: 1m 7s\n",
      "800:\tlearn: 0.0580300\ttest: 0.0600573\tbest: 0.0600573 (800)\ttotal: 41.5s\tremaining: 1m 2s\n",
      "900:\tlearn: 0.0576985\ttest: 0.0599843\tbest: 0.0599843 (900)\ttotal: 46.7s\tremaining: 56.9s\n",
      "1000:\tlearn: 0.0574059\ttest: 0.0599190\tbest: 0.0599190 (1000)\ttotal: 51.8s\tremaining: 51.7s\n",
      "1100:\tlearn: 0.0571209\ttest: 0.0598652\tbest: 0.0598652 (1100)\ttotal: 57.1s\tremaining: 46.6s\n",
      "1200:\tlearn: 0.0568509\ttest: 0.0598219\tbest: 0.0598219 (1200)\ttotal: 1m 2s\tremaining: 41.5s\n",
      "1300:\tlearn: 0.0566091\ttest: 0.0597865\tbest: 0.0597856 (1299)\ttotal: 1m 7s\tremaining: 36.3s\n",
      "1400:\tlearn: 0.0563691\ttest: 0.0597635\tbest: 0.0597634 (1399)\ttotal: 1m 12s\tremaining: 31.1s\n",
      "1500:\tlearn: 0.0561563\ttest: 0.0597393\tbest: 0.0597389 (1499)\ttotal: 1m 18s\tremaining: 25.9s\n",
      "1600:\tlearn: 0.0559299\ttest: 0.0597220\tbest: 0.0597219 (1598)\ttotal: 1m 23s\tremaining: 20.8s\n",
      "1700:\tlearn: 0.0557124\ttest: 0.0597093\tbest: 0.0597093 (1700)\ttotal: 1m 28s\tremaining: 15.5s\n",
      "1800:\tlearn: 0.0554899\ttest: 0.0597009\tbest: 0.0596993 (1752)\ttotal: 1m 33s\tremaining: 10.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.05969929234\n",
      "bestIteration = 1752\n",
      "\n",
      "Shrink model to first 1753 iterations.\n",
      "\n",
      "Fold 5\n",
      "0:\tlearn: 0.9360847\ttest: 0.9367043\tbest: 0.9367043 (0)\ttotal: 44.3ms\tremaining: 1m 28s\n",
      "100:\tlearn: 0.0879269\ttest: 0.0888641\tbest: 0.0888641 (100)\ttotal: 5s\tremaining: 1m 33s\n",
      "200:\tlearn: 0.0619734\ttest: 0.0628935\tbest: 0.0628935 (200)\ttotal: 10.3s\tremaining: 1m 32s\n",
      "300:\tlearn: 0.0604217\ttest: 0.0616068\tbest: 0.0616068 (300)\ttotal: 15.4s\tremaining: 1m 27s\n",
      "400:\tlearn: 0.0597233\ttest: 0.0611443\tbest: 0.0611443 (400)\ttotal: 20.6s\tremaining: 1m 22s\n",
      "500:\tlearn: 0.0591253\ttest: 0.0608454\tbest: 0.0608454 (500)\ttotal: 25.8s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.0586043\ttest: 0.0606542\tbest: 0.0606537 (597)\ttotal: 30.9s\tremaining: 1m 12s\n",
      "700:\tlearn: 0.0582084\ttest: 0.0605336\tbest: 0.0605331 (699)\ttotal: 36.1s\tremaining: 1m 6s\n",
      "800:\tlearn: 0.0578424\ttest: 0.0604425\tbest: 0.0604425 (800)\ttotal: 41.2s\tremaining: 1m 1s\n",
      "900:\tlearn: 0.0575103\ttest: 0.0603756\tbest: 0.0603749 (897)\ttotal: 46.4s\tremaining: 56.6s\n",
      "1000:\tlearn: 0.0572202\ttest: 0.0603171\tbest: 0.0603171 (1000)\ttotal: 51.6s\tremaining: 51.5s\n",
      "1100:\tlearn: 0.0569543\ttest: 0.0602827\tbest: 0.0602827 (1097)\ttotal: 56.8s\tremaining: 46.4s\n",
      "1200:\tlearn: 0.0566857\ttest: 0.0602457\tbest: 0.0602434 (1193)\ttotal: 1m 2s\tremaining: 41.3s\n",
      "1300:\tlearn: 0.0564337\ttest: 0.0602128\tbest: 0.0602124 (1299)\ttotal: 1m 7s\tremaining: 36.4s\n",
      "1400:\tlearn: 0.0561972\ttest: 0.0601854\tbest: 0.0601854 (1400)\ttotal: 1m 13s\tremaining: 31.3s\n",
      "1500:\tlearn: 0.0559655\ttest: 0.0601681\tbest: 0.0601675 (1486)\ttotal: 1m 18s\tremaining: 26.1s\n",
      "1600:\tlearn: 0.0557219\ttest: 0.0601424\tbest: 0.0601424 (1599)\ttotal: 1m 24s\tremaining: 20.9s\n",
      "1700:\tlearn: 0.0555101\ttest: 0.0601323\tbest: 0.0601320 (1696)\ttotal: 1m 29s\tremaining: 15.8s\n",
      "1800:\tlearn: 0.0552925\ttest: 0.0601157\tbest: 0.0601150 (1796)\ttotal: 1m 34s\tremaining: 10.5s\n",
      "1900:\tlearn: 0.0550699\ttest: 0.0601037\tbest: 0.0601021 (1897)\ttotal: 1m 41s\tremaining: 5.29s\n",
      "1999:\tlearn: 0.0548552\ttest: 0.0600947\tbest: 0.0600934 (1993)\ttotal: 1m 46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06009340689\n",
      "bestIteration = 1993\n",
      "\n",
      "Shrink model to first 1994 iterations.\n",
      "\n",
      "OOF RMSLE: 0.05990\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "# Setup\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = test.drop(columns=['id'])\n",
    "categorical_cols = ['Sex']#,'Duration','Age']\n",
    "\n",
    "# Stratify on Duration bins\n",
    "duration_bins = pd.qcut(train['Duration'], q=10, labels=False)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize prediction arrays\n",
    "test_preds_log = np.zeros(len(test))       # accumulate raw predictions (log)\n",
    "test_preds_lin = np.zeros(len(test))       # accumulate converted predictions\n",
    "oof_preds = np.zeros(len(train))           # OOF predictions for validation\n",
    "\n",
    "#X_train['Duration'] = X_train['Duration'].astype(int)\n",
    "#X_test['Duration'] = X_test['Duration'].astype(int)\n",
    "# Cross-validation loop\n",
    "for fold, (idx_tr, idx_val) in enumerate(cv.split(X_train, duration_bins)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[idx_tr], X_train.iloc[idx_val]\n",
    "    y_tr, y_val = np.log1p(y_train.iloc[idx_tr]), np.log1p(y_train.iloc[idx_val])\n",
    "    \n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=categorical_cols)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "    test_pool = Pool(X_test, cat_features=categorical_cols)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        random_strength=5,\n",
    "        l2_leaf_reg=7,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        grow_policy='SymmetricTree',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    \n",
    "    # Predict on test\n",
    "    preds_test_log = model.predict(test_pool)\n",
    "    preds_test_lin = np.expm1(preds_test_log)\n",
    "\n",
    "    test_preds_log += preds_test_log\n",
    "    test_preds_lin += preds_test_lin\n",
    "\n",
    "    # OOF predictions for this fold\n",
    "    oof_preds[idx_val] = np.expm1(model.predict(val_pool))\n",
    "\n",
    "# Average predictions\n",
    "test_preds_log = np.expm1(test_preds_log / cv.get_n_splits())  # average in log space\n",
    "test_preds_lin = test_preds_lin / cv.get_n_splits()            # average in linear space\n",
    "\n",
    "# Compute OOF RMSLE\n",
    "rmsle_oof = np.sqrt(mean_squared_error(np.log1p(y_train), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle_oof:.5f}\")\n",
    "\n",
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_new_age.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_new_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dur_body_heart</th>\n",
       "      <th>BMR</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_x_Duration</th>\n",
       "      <th>Age_x_Heart_Rate</th>\n",
       "      <th>Age_x_Weight</th>\n",
       "      <th>Age_x_Height</th>\n",
       "      <th>Duration_x_Heart_Rate</th>\n",
       "      <th>Duration_x_Weight</th>\n",
       "      <th>Duration_x_Height</th>\n",
       "      <th>Heart_Rate_x_Weight</th>\n",
       "      <th>Heart_Rate_x_Height</th>\n",
       "      <th>Weight_x_Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>22.955684</td>\n",
       "      <td>107666.0</td>\n",
       "      <td>1826.25</td>\n",
       "      <td>...</td>\n",
       "      <td>936.0</td>\n",
       "      <td>3636.0</td>\n",
       "      <td>2952.0</td>\n",
       "      <td>6804.0</td>\n",
       "      <td>2626.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>8282.0</td>\n",
       "      <td>19089.0</td>\n",
       "      <td>15498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>22.582709</td>\n",
       "      <td>26996.0</td>\n",
       "      <td>1137.75</td>\n",
       "      <td>...</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5440.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>10432.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>13855.0</td>\n",
       "      <td>9780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>24.690405</td>\n",
       "      <td>23402.4</td>\n",
       "      <td>1230.25</td>\n",
       "      <td>...</td>\n",
       "      <td>357.0</td>\n",
       "      <td>4284.0</td>\n",
       "      <td>3264.0</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>13524.0</td>\n",
       "      <td>10304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>24.414062</td>\n",
       "      <td>106837.5</td>\n",
       "      <td>2005.00</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>9450.0</td>\n",
       "      <td>20160.0</td>\n",
       "      <td>17280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>22.136740</td>\n",
       "      <td>103530.0</td>\n",
       "      <td>1296.50</td>\n",
       "      <td>...</td>\n",
       "      <td>950.0</td>\n",
       "      <td>3876.0</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>6308.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>16932.0</td>\n",
       "      <td>10126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>male</td>\n",
       "      <td>28</td>\n",
       "      <td>193.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>26.040968</td>\n",
       "      <td>139878.0</td>\n",
       "      <td>2041.25</td>\n",
       "      <td>...</td>\n",
       "      <td>840.0</td>\n",
       "      <td>3192.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>11058.0</td>\n",
       "      <td>22002.0</td>\n",
       "      <td>18721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>23.140496</td>\n",
       "      <td>67068.0</td>\n",
       "      <td>1180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>5888.0</td>\n",
       "      <td>4032.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>5796.0</td>\n",
       "      <td>15180.0</td>\n",
       "      <td>10395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>25.529645</td>\n",
       "      <td>134029.3</td>\n",
       "      <td>1387.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>4020.0</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>4698.0</td>\n",
       "      <td>7571.0</td>\n",
       "      <td>18306.0</td>\n",
       "      <td>10854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>182.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>27.472527</td>\n",
       "      <td>69880.2</td>\n",
       "      <td>1827.50</td>\n",
       "      <td>...</td>\n",
       "      <td>765.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>8190.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>9282.0</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>16562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>female</td>\n",
       "      <td>39</td>\n",
       "      <td>171.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>22.229062</td>\n",
       "      <td>74825.8</td>\n",
       "      <td>1362.75</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>6669.0</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>6305.0</td>\n",
       "      <td>16587.0</td>\n",
       "      <td>11115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  \\\n",
       "0         male   36   189.0    82.0      26.0       101.0       41.0   \n",
       "1       female   64   163.0    60.0       8.0        85.0       39.7   \n",
       "2       female   51   161.0    64.0       7.0        84.0       39.8   \n",
       "3         male   20   192.0    90.0      25.0       105.0       40.7   \n",
       "4       female   38   166.0    61.0      25.0       102.0       40.6   \n",
       "...        ...  ...     ...     ...       ...         ...        ...   \n",
       "749995    male   28   193.0    97.0      30.0       114.0       40.9   \n",
       "749996  female   64   165.0    63.0      18.0        92.0       40.5   \n",
       "749997    male   60   162.0    67.0      29.0       113.0       40.9   \n",
       "749998    male   45   182.0    91.0      17.0       102.0       40.3   \n",
       "749999  female   39   171.0    65.0      19.0        97.0       40.6   \n",
       "\n",
       "              bmi  dur_body_heart      BMR  ...  Age_x_Duration  \\\n",
       "0       22.955684        107666.0  1826.25  ...           936.0   \n",
       "1       22.582709         26996.0  1137.75  ...           512.0   \n",
       "2       24.690405         23402.4  1230.25  ...           357.0   \n",
       "3       24.414062        106837.5  2005.00  ...           500.0   \n",
       "4       22.136740        103530.0  1296.50  ...           950.0   \n",
       "...           ...             ...      ...  ...             ...   \n",
       "749995  26.040968        139878.0  2041.25  ...           840.0   \n",
       "749996  23.140496         67068.0  1180.25  ...          1152.0   \n",
       "749997  25.529645        134029.3  1387.50  ...          1740.0   \n",
       "749998  27.472527         69880.2  1827.50  ...           765.0   \n",
       "749999  22.229062         74825.8  1362.75  ...           741.0   \n",
       "\n",
       "        Age_x_Heart_Rate  Age_x_Weight  Age_x_Height  Duration_x_Heart_Rate  \\\n",
       "0                 3636.0        2952.0        6804.0                 2626.0   \n",
       "1                 5440.0        3840.0       10432.0                  680.0   \n",
       "2                 4284.0        3264.0        8211.0                  588.0   \n",
       "3                 2100.0        1800.0        3840.0                 2625.0   \n",
       "4                 3876.0        2318.0        6308.0                 2550.0   \n",
       "...                  ...           ...           ...                    ...   \n",
       "749995            3192.0        2716.0        5404.0                 3420.0   \n",
       "749996            5888.0        4032.0       10560.0                 1656.0   \n",
       "749997            6780.0        4020.0        9720.0                 3277.0   \n",
       "749998            4590.0        4095.0        8190.0                 1734.0   \n",
       "749999            3783.0        2535.0        6669.0                 1843.0   \n",
       "\n",
       "        Duration_x_Weight  Duration_x_Height  Heart_Rate_x_Weight  \\\n",
       "0                  2132.0             4914.0               8282.0   \n",
       "1                   480.0             1304.0               5100.0   \n",
       "2                   448.0             1127.0               5376.0   \n",
       "3                  2250.0             4800.0               9450.0   \n",
       "4                  1525.0             4150.0               6222.0   \n",
       "...                   ...                ...                  ...   \n",
       "749995             2910.0             5790.0              11058.0   \n",
       "749996             1134.0             2970.0               5796.0   \n",
       "749997             1943.0             4698.0               7571.0   \n",
       "749998             1547.0             3094.0               9282.0   \n",
       "749999             1235.0             3249.0               6305.0   \n",
       "\n",
       "        Heart_Rate_x_Height  Weight_x_Height  \n",
       "0                   19089.0          15498.0  \n",
       "1                   13855.0           9780.0  \n",
       "2                   13524.0          10304.0  \n",
       "3                   20160.0          17280.0  \n",
       "4                   16932.0          10126.0  \n",
       "...                     ...              ...  \n",
       "749995              22002.0          18721.0  \n",
       "749996              15180.0          10395.0  \n",
       "749997              18306.0          10854.0  \n",
       "749998              18564.0          16562.0  \n",
       "749999              16587.0          11115.0  \n",
       "\n",
       "[750000 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_age_cat.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_age_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[categorical_cols].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  Calories_xgb  Calories_cat  Calories_avg  Calories_log_avg\n",
      "0  750000     27.541962     27.134063     27.338013         27.337279\n",
      "1  750001    108.137621    107.451112    107.794366        107.793825\n",
      "2  750002     87.279698     88.094149     87.686924         87.685989\n",
      "3  750003    125.480219    125.700810    125.590514        125.590466\n",
      "4  750004     76.096430     75.849336     75.972883         75.972784\n"
     ]
    }
   ],
   "source": [
    "data1=pd.read_csv('submission_xgb_new (1).csv')\n",
    "data2=pd.read_csv('catboost_log_avg (2).csv')\n",
    "\n",
    "data = data1.merge(data2, on='id', suffixes=('_xgb', '_cat'))\n",
    "\n",
    "\n",
    "# 1. Simple average of the two predictions\n",
    "data['Calories_avg'] = (data['Calories_xgb'] + data['Calories_cat']) / 2\n",
    "\n",
    "# 2. Log-scale average (RMSLE-style averaging)\n",
    "data['Calories_log_avg'] = np.expm1(\n",
    "    (np.log1p(data['Calories_xgb']) + np.log1p(data['Calories_cat'])) / 2\n",
    ")\n",
    "\n",
    "print(data[['id', 'Calories_xgb', 'Calories_cat', 'Calories_avg', 'Calories_log_avg']].head())\n",
    "data[['id', 'Calories_avg']].rename(columns={'Calories_avg': 'Calories'}).to_csv('submission_reg_avg_2.csv', index=False)\n",
    "\n",
    "# Save log-scale average with 'Calories' as the second column\n",
    "data[['id', 'Calories_log_avg']].rename(columns={'Calories_log_avg': 'Calories'}).to_csv('submission_log_avg_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
