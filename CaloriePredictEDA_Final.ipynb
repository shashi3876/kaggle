{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj0O63RU53jX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "THis notebook contains he final notebook submission to the Kaggle competion predcit Calories challenge. I will start by first havoing code to the best possible solution based on the public leaderboard) and then explore other options. EDA and other stuff have been removed from this notebook for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vDPkI88a0LAu"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zFS_dZcX0PWt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6tkK3r9Bcxu"
   },
   "source": [
    "# Use of CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPvK2LUpBs9M"
   },
   "outputs": [],
   "source": [
    "# Define columns to exclude from features\n",
    "exclude_cols = ['id', 'Calories']\n",
    "target_col = 'Calories'\n",
    "\n",
    "# Split features and target from train\n",
    "X_train = train.drop(columns=exclude_cols)\n",
    "y_train = train[target_col]\n",
    "\n",
    "# Prepare test set (same feature columns)\n",
    "X_test = test.drop(columns=['id'])\n",
    "\n",
    "# Identify categorical features (assumes object types are categorical)\n",
    "categorical_features = ['Sex']\n",
    "\n",
    "# Optional: split validation set from train (for early stopping)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Pools\n",
    "train_pool = Pool(X_tr, y_tr, cat_features=categorical_features)\n",
    "val_pool = Pool(X_val, y_val, cat_features=categorical_features)\n",
    "test_pool = Pool(X_test, cat_features=categorical_features)\n",
    "\n",
    "# Train the model\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=10,\n",
    "    random_strength=5,\n",
    "    l2_leaf_reg=7,\n",
    "    bootstrap_type='Bernoulli',\n",
    "    grow_policy='SymmetricTree',\n",
    "    eval_metric='RMSE',\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# Predict on test set\n",
    "test_preds = model.predict(test_pool)\n",
    "\n",
    "# Add predictions to test dataframe\n",
    "test['Calories'] = test_preds\n",
    "\n",
    "# Optional: preview results\n",
    "print(test[['id','Calories']].head())\n",
    "test[['id','Calories']].to_csv('catboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bin 'Duration' into quantile-based categories (e.g., 5 groups)\n",
    "X_train = train.drop(columns=exclude_cols)\n",
    "y_train = train[target_col]\n",
    "\n",
    "# Add Duration binning for stratification\n",
    "duration_bins = pd.qcut(train['Duration'], q=10, labels=False)  # or use pd.cut for fixed bins\n",
    "\n",
    "# Initialize StratifiedKFold using duration bins\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "\n",
    "# Proceed with the same logic â€” just replace KFold with StratifiedKFold\n",
    "for fold, (idx_train, idx_valid) in enumerate(cv.split(X_train, duration_bins)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[idx_train], X_train.iloc[idx_valid]\n",
    "    y_tr, y_val = np.log1p(y_train.iloc[idx_train]), np.log1p(y_train.iloc[idx_valid])\n",
    "    \n",
    "    # CatBoost Pools\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=categorical_features)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_features)\n",
    "    test_pool = Pool(X_test, cat_features=categorical_features)\n",
    "    \n",
    "    # Train and predict as before...\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        random_strength=5,\n",
    "        l2_leaf_reg=7,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        grow_policy='SymmetricTree',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    test_preds += np.expm1(model.predict(test_pool))\n",
    "\n",
    "test_preds /= cv.get_n_splits()\n",
    "test['Calories'] = test_preds\n",
    "test[['id','Calories']].to_csv('catboost_5_fold_str.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "categorical_cols = ['Sex']\n",
    "\n",
    "# Discretize 'duration' into 5 bins for stratification\n",
    "duration_bins = pd.qcut(X['Duration'], q=5, labels=False, duplicates='drop')\n",
    "\n",
    "# Use StratifiedKFold for stratified splitting based on duration bins\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "y_pred = np.zeros(len(test))\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)  # log(1 + y) for RMSLE-friendly training\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, duration_bins):\n",
    "    X_train, y_train = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target Encoding for categorical column\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',  # L2 loss\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "\n",
    "# Average predictions over folds\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# Create submission file\n",
    "pred_xgb = y_pred\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': pred_xgb})\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENsemble the two best cases (In log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('submission_xgb (1).csv')\n",
    "data2=pd.read_csv('catboost_5_fold_str (1).csv')\n",
    "\n",
    "data = data1.merge(data2, on='id', suffixes=('_xgb', '_cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 1. Simple average of the two predictions\n",
    "data['Calories_avg'] = (data['Calories_xgb'] + data['Calories_cat']) / 2\n",
    "\n",
    "# 2. Log-scale average (RMSLE-style averaging)\n",
    "data['Calories_log_avg'] = np.expm1(\n",
    "    (np.log1p(data['Calories_xgb']) + np.log1p(data['Calories_cat'])) / 2\n",
    ")\n",
    "\n",
    "print(data[['id', 'Calories_xgb', 'Calories_cat', 'Calories_avg', 'Calories_log_avg']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simple average with 'Calories' as the second column\n",
    "data[['id', 'Calories_avg']].rename(columns={'Calories_avg': 'Calories'}).to_csv('submission_reg_avg.csv', index=False)\n",
    "\n",
    "# Save log-scale average with 'Calories' as the second column\n",
    "data[['id', 'Calories_log_avg']].rename(columns={'Calories_log_avg': 'Calories'}).to_csv('submission_log_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fresh with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain['Duration_2'] = train['Duration']\\ntest['Duration_2'] = test['Duration']\\n\\ntrain['Age_2'] = train['Age']\\ntest['Age_2'] = test['Age']\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n",
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)\n",
    "\n",
    "# Squares of features\n",
    "train['dur_2']=train['Duration']*train['Duration']\n",
    "test['dur_2']=test['Duration']*test['Duration']\n",
    "\n",
    "train['hr_2']=train['Heart_Rate']*train['Heart_Rate']\n",
    "test['hr_2']=test['Heart_Rate']*test['Heart_Rate']\n",
    "\n",
    "train['height_2']=train['Height']*train['Height']\n",
    "test['height_2']=test['Height']*test['Height']\n",
    "\n",
    "train['weight_2']=train['Weight']*train['Weight']\n",
    "test['weight_2']=test['Weight']*test['Weight']\n",
    "\n",
    "# Square root of Duration\n",
    "train['dur_sqrt'] = train['Duration'] ** 0.5\n",
    "test['dur_sqrt'] = test['Duration'] ** 0.5\n",
    "\n",
    "train['hr_sqrt'] = train['Heart_Rate'] ** 0.5\n",
    "test['hr_sqrt'] = test['Heart_Rate'] ** 0.5\n",
    "\n",
    "train['weight_sqrt'] = train['Weight'] ** 0.5\n",
    "test['weight_sqrt'] = test['Weight'] ** 0.5\n",
    "\n",
    "train['height_sqrt'] = train['Height'] ** 0.5\n",
    "test['height_sqrt'] = test['Height'] ** 0.5\n",
    "\n",
    "train['Intensity'] = train['Heart_Rate'] / train['Duration']\n",
    "test['Intensity'] = test['Heart_Rate'] / test['Duration']\n",
    "\n",
    "# Create binary indicators\n",
    "train['is_male'] = (train['Sex'].str.lower() == 'male').astype(int)\n",
    "train['is_female'] = (train['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "test['is_male'] = (test['Sex'].str.lower() == 'male').astype(int)\n",
    "test['is_female'] = (test['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "# Numerical columns to interact with sex\n",
    "num_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height', 'Body_Temp','bmi','Intensity','dur_body_heart']\n",
    "\n",
    "# Create interaction features\n",
    "for col in num_cols:\n",
    "    train[f'{col}_Male'] = train[col] * train['is_male']\n",
    "    train[f'{col}_Female'] = train[col] * train['is_female']\n",
    "\n",
    "    test[f'{col}_Male'] = test[col] * test['is_male']\n",
    "    test[f'{col}_Female'] = test[col] * test['is_female']\n",
    "\n",
    "\n",
    "for col in ['Weight', 'Height', 'Duration', 'Heart_Rate', 'Body_Temp']:\n",
    "    train[f'{col}_log'] = np.log1p(train[col])\n",
    "    test[f'{col}_log'] = np.log1p(test[col])\n",
    "\n",
    "train['Weight_Height_ratio'] = train['Weight'] / train['Height']\n",
    "test['Weight_Height_ratio'] = test['Weight'] / test['Height']\n",
    "\n",
    "train['HeartRate_BodyTemp_ratio'] = train['Heart_Rate'] / train['Body_Temp']\n",
    "test['HeartRate_BodyTemp_ratio'] = test['Heart_Rate'] / test['Body_Temp']\n",
    "\n",
    "\n",
    "train['effort_per_kg'] = train['Duration'] * train['Heart_Rate'] / train['Weight']\n",
    "test['effort_per_kg'] = test['Duration'] * test['Heart_Rate'] / test['Weight']\n",
    "\n",
    "\n",
    "train['Age_HeartRate'] = train['Age'] * train['Heart_Rate']\n",
    "test['Age_HeartRate'] = test['Age'] * test['Heart_Rate']\n",
    "\n",
    "train['Temp_Height'] = train['Body_Temp'] * train['Height']\n",
    "test['Temp_Height'] = test['Body_Temp'] * test['Height']\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "poly_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height']\n",
    "for col1, col2 in combinations(poly_cols, 2):\n",
    "    train[f'{col1}_x_{col2}'] = train[col1] * train[col2]\n",
    "    test[f'{col1}_x_{col2}'] = test[col1] * test[col2]\n",
    "'''\n",
    "train['Duration_2'] = train['Duration']\n",
    "test['Duration_2'] = test['Duration']\n",
    "\n",
    "train['Age_2'] = train['Age']\n",
    "test['Age_2'] = test['Age']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex']\n",
    "\n",
    "categorical_cols = ['Sex']\n",
    "\n",
    "# Discretize 'duration' into 5 bins for stratification\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Use StratifiedKFold for stratified splitting based on duration bins\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "y_pred = np.zeros(len(test))\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)  # log(1 + y) for RMSLE-friendly training\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, duration_bins):\n",
    "    X_train, y_train = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target Encoding for categorical column\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',  # L2 loss\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "\n",
    "# Average predictions over folds\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# Create submission file\n",
    "pred_xgb = y_pred\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': pred_xgb})\n",
    "submission_xgb.to_csv('submission_xgb_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex','Duration','Age']\n",
    "\n",
    "# Stratification based on binned Duration\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Initialize predictions\n",
    "y_pred = np.zeros(len(test))\n",
    "oof_preds = np.zeros(len(train))  # To store OOF predictions\n",
    "\n",
    "for idx_fold, (idx_train, idx_valid) in enumerate(cv.split(X, duration_bins)):\n",
    "    print(f\"\\nFold {idx_fold + 1}\")\n",
    "    \n",
    "    X_train, y_train_fold = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid_fold = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    # Target encoding\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train['Sex'] = encoder.fit_transform(X_train[['Sex']], y_train_fold)[:, 0]\n",
    "    X_valid['Sex'] = encoder.transform(X_valid[['Sex']])[:, 0]\n",
    "    X_test['Sex'] = encoder.transform(X_test[['Sex']])[:, 0]\n",
    "\n",
    "    # Model\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_fold,\n",
    "        eval_set=[(X_valid, y_valid_fold)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Predict on test and validation sets\n",
    "    y_pred += np.expm1(model.predict(X_test))\n",
    "    oof_preds[idx_valid] = np.expm1(model.predict(X_valid))\n",
    "\n",
    "# Final test prediction (average)\n",
    "y_pred /= cv.get_n_splits()\n",
    "\n",
    "# OOF RMSLE\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(train['Calories']), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "# Submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': y_pred})\n",
    "submission_xgb.to_csv('submission_xgb_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF RMSLE: 0.05991 => with ratio features\n",
    "OOF RMSLE: 0.05993 => with ratio features + efficiency\n",
    "OOF RMSLE: 0.05988 => with ratio features + efficiency + interation\n",
    "OOF RMSLE: 0.05985 => with ratio features + efficiency + interation + pairwise polynomial\n",
    "OOF RMSLE: 0.05994 => with ratio features +            + interation + pairwise polynomial\n",
    "\n",
    "\n",
    "OOF RMSLE: 0.05983 => with ratio features +  effciency + interation + pairwise polynomial with Duration as a cxategory\n",
    "OOF RMSLE: 0.05983 => with ratio features +  effciency + interation + pairwise polynomial with Duration and Age as a cxategory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex','Duration','Age']\n",
    "categorical_cols = ['Sex','Duration']#,'Age']\n",
    "# Stratification based on binned Duration\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Initialize predictions\n",
    "y_pred = np.zeros(len(test))\n",
    "oof_preds = np.zeros(len(train))  # To store OOF predictions\n",
    "\n",
    "for idx_fold, (idx_train, idx_valid) in enumerate(cv.split(X, duration_bins)):\n",
    "    print(f\"\\nFold {idx_fold + 1}\")\n",
    "    \n",
    "    X_train, y_train_fold = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid_fold = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train_fold)\n",
    "    X_valid[categorical_cols] = encoder.transform(X_valid[categorical_cols])\n",
    "    X_test[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Model\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_fold,\n",
    "        eval_set=[(X_valid, y_valid_fold)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Predict on test and validation sets\n",
    "    y_pred += model.predict(X_test)\n",
    "    oof_preds[idx_valid] = np.expm1(model.predict(X_valid))\n",
    "\n",
    "# Final test prediction (average)\n",
    "y_pred = np.expm1(y_pred / cv.get_n_splits()) \n",
    "\n",
    "# OOF RMSLE\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(train['Calories']), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "# Submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': y_pred})\n",
    "submission_xgb.to_csv('submission_xgb_category.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "0:\tlearn: 0.9364480\ttest: 0.9352710\tbest: 0.9352710 (0)\ttotal: 232ms\tremaining: 7m 44s\n",
      "100:\tlearn: 0.0872081\ttest: 0.0874004\tbest: 0.0874004 (100)\ttotal: 15.1s\tremaining: 4m 44s\n",
      "200:\tlearn: 0.0620141\ttest: 0.0629999\tbest: 0.0629999 (200)\ttotal: 31.9s\tremaining: 4m 45s\n",
      "300:\tlearn: 0.0606434\ttest: 0.0619923\tbest: 0.0619923 (300)\ttotal: 52.3s\tremaining: 4m 55s\n",
      "400:\tlearn: 0.0599739\ttest: 0.0615641\tbest: 0.0615641 (400)\ttotal: 1m 5s\tremaining: 4m 19s\n",
      "500:\tlearn: 0.0593572\ttest: 0.0612315\tbest: 0.0612315 (500)\ttotal: 1m 16s\tremaining: 3m 48s\n",
      "600:\tlearn: 0.0588224\ttest: 0.0610167\tbest: 0.0610167 (600)\ttotal: 1m 29s\tremaining: 3m 27s\n",
      "700:\tlearn: 0.0583685\ttest: 0.0608855\tbest: 0.0608850 (698)\ttotal: 1m 40s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0579891\ttest: 0.0607698\tbest: 0.0607687 (798)\ttotal: 1m 52s\tremaining: 2m 47s\n",
      "900:\tlearn: 0.0576433\ttest: 0.0606854\tbest: 0.0606854 (900)\ttotal: 2m 3s\tremaining: 2m 30s\n",
      "1000:\tlearn: 0.0573236\ttest: 0.0606163\tbest: 0.0606163 (1000)\ttotal: 2m 14s\tremaining: 2m 13s\n",
      "1100:\tlearn: 0.0569982\ttest: 0.0605560\tbest: 0.0605560 (1100)\ttotal: 2m 28s\tremaining: 2m\n",
      "1200:\tlearn: 0.0567235\ttest: 0.0605067\tbest: 0.0605067 (1200)\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1300:\tlearn: 0.0564767\ttest: 0.0604707\tbest: 0.0604707 (1300)\ttotal: 2m 50s\tremaining: 1m 31s\n",
      "1400:\tlearn: 0.0562332\ttest: 0.0604394\tbest: 0.0604394 (1400)\ttotal: 3m 2s\tremaining: 1m 17s\n",
      "1500:\tlearn: 0.0559833\ttest: 0.0604124\tbest: 0.0604116 (1497)\ttotal: 3m 13s\tremaining: 1m 4s\n",
      "1600:\tlearn: 0.0557484\ttest: 0.0603997\tbest: 0.0603994 (1598)\ttotal: 3m 27s\tremaining: 51.6s\n",
      "1700:\tlearn: 0.0555089\ttest: 0.0603832\tbest: 0.0603832 (1682)\ttotal: 3m 40s\tremaining: 38.8s\n",
      "1800:\tlearn: 0.0552762\ttest: 0.0603584\tbest: 0.0603584 (1800)\ttotal: 3m 54s\tremaining: 25.9s\n",
      "1900:\tlearn: 0.0550597\ttest: 0.0603399\tbest: 0.0603388 (1899)\ttotal: 4m 5s\tremaining: 12.8s\n",
      "1999:\tlearn: 0.0548477\ttest: 0.0603309\tbest: 0.0603306 (1972)\ttotal: 4m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06033059342\n",
      "bestIteration = 1972\n",
      "\n",
      "Shrink model to first 1973 iterations.\n",
      "\n",
      "Fold 2\n",
      "0:\tlearn: 0.9361378\ttest: 0.9367265\tbest: 0.9367265 (0)\ttotal: 125ms\tremaining: 4m 9s\n",
      "100:\tlearn: 0.0876587\ttest: 0.0867112\tbest: 0.0867112 (100)\ttotal: 11.9s\tremaining: 3m 44s\n",
      "200:\tlearn: 0.0624005\ttest: 0.0614875\tbest: 0.0614875 (200)\ttotal: 24.2s\tremaining: 3m 36s\n",
      "300:\tlearn: 0.0609019\ttest: 0.0603377\tbest: 0.0603377 (300)\ttotal: 36s\tremaining: 3m 23s\n",
      "400:\tlearn: 0.0601717\ttest: 0.0598663\tbest: 0.0598663 (400)\ttotal: 47.1s\tremaining: 3m 7s\n",
      "500:\tlearn: 0.0595405\ttest: 0.0595001\tbest: 0.0595001 (500)\ttotal: 59.1s\tremaining: 2m 56s\n",
      "600:\tlearn: 0.0590087\ttest: 0.0592740\tbest: 0.0592740 (600)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "700:\tlearn: 0.0585800\ttest: 0.0591303\tbest: 0.0591303 (700)\ttotal: 1m 22s\tremaining: 2m 33s\n",
      "800:\tlearn: 0.0582224\ttest: 0.0590121\tbest: 0.0590121 (800)\ttotal: 1m 34s\tremaining: 2m 20s\n",
      "900:\tlearn: 0.0578830\ttest: 0.0589219\tbest: 0.0589217 (899)\ttotal: 1m 45s\tremaining: 2m 8s\n",
      "1000:\tlearn: 0.0575600\ttest: 0.0588580\tbest: 0.0588577 (999)\ttotal: 1m 57s\tremaining: 1m 56s\n",
      "1100:\tlearn: 0.0572711\ttest: 0.0588002\tbest: 0.0588002 (1100)\ttotal: 2m 8s\tremaining: 1m 45s\n",
      "1200:\tlearn: 0.0569974\ttest: 0.0587647\tbest: 0.0587647 (1200)\ttotal: 2m 20s\tremaining: 1m 33s\n",
      "1300:\tlearn: 0.0567309\ttest: 0.0587279\tbest: 0.0587279 (1300)\ttotal: 2m 32s\tremaining: 1m 21s\n",
      "1400:\tlearn: 0.0564556\ttest: 0.0586917\tbest: 0.0586917 (1400)\ttotal: 2m 43s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.0562195\ttest: 0.0586657\tbest: 0.0586655 (1499)\ttotal: 2m 55s\tremaining: 58.2s\n",
      "1600:\tlearn: 0.0559746\ttest: 0.0586415\tbest: 0.0586407 (1598)\ttotal: 3m 7s\tremaining: 46.7s\n",
      "1700:\tlearn: 0.0557366\ttest: 0.0586220\tbest: 0.0586220 (1700)\ttotal: 3m 19s\tremaining: 35s\n",
      "1800:\tlearn: 0.0555179\ttest: 0.0586046\tbest: 0.0586046 (1800)\ttotal: 3m 30s\tremaining: 23.2s\n",
      "1900:\tlearn: 0.0552921\ttest: 0.0585960\tbest: 0.0585960 (1900)\ttotal: 3m 41s\tremaining: 11.6s\n",
      "1999:\tlearn: 0.0550701\ttest: 0.0585862\tbest: 0.0585857 (1998)\ttotal: 3m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.05858567273\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "\n",
      "Fold 3\n",
      "0:\tlearn: 0.9365490\ttest: 0.9355334\tbest: 0.9355334 (0)\ttotal: 110ms\tremaining: 3m 39s\n",
      "100:\tlearn: 0.0877334\ttest: 0.0883308\tbest: 0.0883308 (100)\ttotal: 11.1s\tremaining: 3m 28s\n",
      "200:\tlearn: 0.0620053\ttest: 0.0635172\tbest: 0.0635172 (200)\ttotal: 22.5s\tremaining: 3m 21s\n",
      "300:\tlearn: 0.0606506\ttest: 0.0624474\tbest: 0.0624474 (300)\ttotal: 33s\tremaining: 3m 6s\n",
      "400:\tlearn: 0.0599895\ttest: 0.0619682\tbest: 0.0619682 (400)\ttotal: 44.3s\tremaining: 2m 56s\n",
      "500:\tlearn: 0.0594171\ttest: 0.0615876\tbest: 0.0615876 (500)\ttotal: 55.6s\tremaining: 2m 46s\n",
      "600:\tlearn: 0.0588802\ttest: 0.0613248\tbest: 0.0613248 (600)\ttotal: 1m 6s\tremaining: 2m 35s\n",
      "700:\tlearn: 0.0584433\ttest: 0.0611522\tbest: 0.0611522 (700)\ttotal: 1m 18s\tremaining: 2m 24s\n",
      "800:\tlearn: 0.0580857\ttest: 0.0610281\tbest: 0.0610281 (800)\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.0577526\ttest: 0.0609283\tbest: 0.0609283 (900)\ttotal: 1m 44s\tremaining: 2m 7s\n",
      "1000:\tlearn: 0.0574476\ttest: 0.0608464\tbest: 0.0608464 (1000)\ttotal: 1m 56s\tremaining: 1m 56s\n",
      "1100:\tlearn: 0.0571367\ttest: 0.0607853\tbest: 0.0607853 (1100)\ttotal: 2m 8s\tremaining: 1m 44s\n",
      "1200:\tlearn: 0.0568446\ttest: 0.0607420\tbest: 0.0607416 (1196)\ttotal: 2m 19s\tremaining: 1m 33s\n",
      "1300:\tlearn: 0.0565856\ttest: 0.0607040\tbest: 0.0607033 (1297)\ttotal: 2m 31s\tremaining: 1m 21s\n",
      "1400:\tlearn: 0.0563246\ttest: 0.0606783\tbest: 0.0606781 (1397)\ttotal: 2m 43s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.0560866\ttest: 0.0606510\tbest: 0.0606510 (1500)\ttotal: 2m 55s\tremaining: 58.3s\n",
      "1600:\tlearn: 0.0558484\ttest: 0.0606368\tbest: 0.0606368 (1600)\ttotal: 3m 6s\tremaining: 46.5s\n",
      "1700:\tlearn: 0.0556234\ttest: 0.0606105\tbest: 0.0606103 (1699)\ttotal: 3m 18s\tremaining: 34.8s\n",
      "1800:\tlearn: 0.0553927\ttest: 0.0605921\tbest: 0.0605921 (1800)\ttotal: 3m 29s\tremaining: 23.2s\n",
      "1900:\tlearn: 0.0551647\ttest: 0.0605754\tbest: 0.0605754 (1900)\ttotal: 3m 41s\tremaining: 11.5s\n",
      "1999:\tlearn: 0.0549455\ttest: 0.0605625\tbest: 0.0605622 (1991)\ttotal: 3m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06056218836\n",
      "bestIteration = 1991\n",
      "\n",
      "Shrink model to first 1992 iterations.\n",
      "\n",
      "Fold 4\n",
      "0:\tlearn: 0.9360485\ttest: 0.9370800\tbest: 0.9370800 (0)\ttotal: 108ms\tremaining: 3m 36s\n",
      "100:\tlearn: 0.0871843\ttest: 0.0876143\tbest: 0.0876143 (100)\ttotal: 11.3s\tremaining: 3m 31s\n",
      "200:\tlearn: 0.0619947\ttest: 0.0625193\tbest: 0.0625193 (200)\ttotal: 22.1s\tremaining: 3m 17s\n",
      "300:\tlearn: 0.0606374\ttest: 0.0614013\tbest: 0.0614013 (300)\ttotal: 34.1s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.0598967\ttest: 0.0608953\tbest: 0.0608953 (400)\ttotal: 44.8s\tremaining: 2m 58s\n",
      "500:\tlearn: 0.0593458\ttest: 0.0605688\tbest: 0.0605688 (500)\ttotal: 56.2s\tremaining: 2m 48s\n",
      "600:\tlearn: 0.0588223\ttest: 0.0603335\tbest: 0.0603335 (600)\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "700:\tlearn: 0.0583819\ttest: 0.0601735\tbest: 0.0601735 (700)\ttotal: 1m 18s\tremaining: 2m 26s\n",
      "800:\tlearn: 0.0579852\ttest: 0.0600474\tbest: 0.0600474 (800)\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.0576555\ttest: 0.0599664\tbest: 0.0599664 (900)\ttotal: 1m 41s\tremaining: 2m 4s\n",
      "1000:\tlearn: 0.0573408\ttest: 0.0599013\tbest: 0.0599013 (998)\ttotal: 1m 52s\tremaining: 1m 52s\n",
      "1100:\tlearn: 0.0570451\ttest: 0.0598556\tbest: 0.0598544 (1096)\ttotal: 2m 4s\tremaining: 1m 41s\n",
      "1200:\tlearn: 0.0567794\ttest: 0.0598095\tbest: 0.0598095 (1200)\ttotal: 2m 15s\tremaining: 1m 30s\n",
      "1300:\tlearn: 0.0565145\ttest: 0.0597682\tbest: 0.0597682 (1300)\ttotal: 2m 27s\tremaining: 1m 19s\n",
      "1400:\tlearn: 0.0562726\ttest: 0.0597430\tbest: 0.0597430 (1400)\ttotal: 2m 39s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.0560227\ttest: 0.0597203\tbest: 0.0597203 (1500)\ttotal: 2m 51s\tremaining: 57s\n",
      "1600:\tlearn: 0.0558015\ttest: 0.0596947\tbest: 0.0596947 (1600)\ttotal: 3m 3s\tremaining: 45.8s\n",
      "1700:\tlearn: 0.0555638\ttest: 0.0596720\tbest: 0.0596712 (1690)\ttotal: 3m 15s\tremaining: 34.4s\n",
      "1800:\tlearn: 0.0553451\ttest: 0.0596494\tbest: 0.0596488 (1799)\ttotal: 3m 27s\tremaining: 22.9s\n",
      "1900:\tlearn: 0.0551375\ttest: 0.0596318\tbest: 0.0596307 (1888)\ttotal: 3m 39s\tremaining: 11.4s\n",
      "1999:\tlearn: 0.0549009\ttest: 0.0596148\tbest: 0.0596142 (1991)\ttotal: 3m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.05961422007\n",
      "bestIteration = 1991\n",
      "\n",
      "Shrink model to first 1992 iterations.\n",
      "\n",
      "Fold 5\n",
      "0:\tlearn: 0.9362158\ttest: 0.9367947\tbest: 0.9367947 (0)\ttotal: 123ms\tremaining: 4m 6s\n",
      "100:\tlearn: 0.0875512\ttest: 0.0885413\tbest: 0.0885413 (100)\ttotal: 12.2s\tremaining: 3m 48s\n",
      "200:\tlearn: 0.0620155\ttest: 0.0629902\tbest: 0.0629902 (200)\ttotal: 23.3s\tremaining: 3m 28s\n",
      "300:\tlearn: 0.0605993\ttest: 0.0618455\tbest: 0.0618455 (300)\ttotal: 34.8s\tremaining: 3m 16s\n",
      "400:\tlearn: 0.0599097\ttest: 0.0614066\tbest: 0.0614066 (400)\ttotal: 45.9s\tremaining: 3m 3s\n",
      "500:\tlearn: 0.0592925\ttest: 0.0610682\tbest: 0.0610682 (500)\ttotal: 57.4s\tremaining: 2m 51s\n",
      "600:\tlearn: 0.0587373\ttest: 0.0608313\tbest: 0.0608313 (600)\ttotal: 1m 9s\tremaining: 2m 40s\n",
      "700:\tlearn: 0.0582746\ttest: 0.0606631\tbest: 0.0606631 (700)\ttotal: 1m 20s\tremaining: 2m 29s\n",
      "800:\tlearn: 0.0578926\ttest: 0.0605610\tbest: 0.0605610 (800)\ttotal: 1m 32s\tremaining: 2m 18s\n",
      "900:\tlearn: 0.0575277\ttest: 0.0604674\tbest: 0.0604674 (900)\ttotal: 1m 44s\tremaining: 2m 6s\n",
      "1000:\tlearn: 0.0571996\ttest: 0.0603849\tbest: 0.0603848 (999)\ttotal: 1m 55s\tremaining: 1m 55s\n",
      "1100:\tlearn: 0.0569204\ttest: 0.0603336\tbest: 0.0603328 (1097)\ttotal: 2m 6s\tremaining: 1m 43s\n",
      "1200:\tlearn: 0.0566440\ttest: 0.0602907\tbest: 0.0602907 (1200)\ttotal: 2m 19s\tremaining: 1m 32s\n",
      "1300:\tlearn: 0.0563895\ttest: 0.0602510\tbest: 0.0602510 (1300)\ttotal: 2m 31s\tremaining: 1m 21s\n",
      "1400:\tlearn: 0.0561372\ttest: 0.0602237\tbest: 0.0602237 (1400)\ttotal: 2m 42s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.0558911\ttest: 0.0602073\tbest: 0.0602073 (1500)\ttotal: 2m 54s\tremaining: 57.9s\n",
      "1600:\tlearn: 0.0556670\ttest: 0.0601803\tbest: 0.0601802 (1599)\ttotal: 3m 5s\tremaining: 46.2s\n",
      "1700:\tlearn: 0.0554287\ttest: 0.0601536\tbest: 0.0601528 (1696)\ttotal: 3m 16s\tremaining: 34.6s\n",
      "1800:\tlearn: 0.0552055\ttest: 0.0601292\tbest: 0.0601292 (1800)\ttotal: 3m 29s\tremaining: 23.1s\n",
      "1900:\tlearn: 0.0549900\ttest: 0.0601160\tbest: 0.0601160 (1900)\ttotal: 3m 41s\tremaining: 11.5s\n",
      "1999:\tlearn: 0.0547704\ttest: 0.0600935\tbest: 0.0600934 (1998)\ttotal: 3m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.0600934407\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "\n",
      "OOF RMSLE: 0.05984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "# Setup\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = test.drop(columns=['id'])\n",
    "categorical_cols = ['Sex','Duration','Age']\n",
    "\n",
    "# Stratify on Duration bins\n",
    "duration_bins = pd.qcut(train['Duration'], q=10, labels=False)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize prediction arrays\n",
    "test_preds_log = np.zeros(len(test))       # accumulate raw predictions (log)\n",
    "test_preds_lin = np.zeros(len(test))       # accumulate converted predictions\n",
    "oof_preds = np.zeros(len(train))           # OOF predictions for validation\n",
    "\n",
    "X_train['Duration'] = X_train['Duration'].astype(int)\n",
    "X_test['Duration'] = X_test['Duration'].astype(int)\n",
    "# Cross-validation loop\n",
    "for fold, (idx_tr, idx_val) in enumerate(cv.split(X_train, duration_bins)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[idx_tr], X_train.iloc[idx_val]\n",
    "    y_tr, y_val = np.log1p(y_train.iloc[idx_tr]), np.log1p(y_train.iloc[idx_val])\n",
    "    \n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=categorical_cols)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "    test_pool = Pool(X_test, cat_features=categorical_cols)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        random_strength=5,\n",
    "        l2_leaf_reg=7,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        grow_policy='SymmetricTree',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    \n",
    "    # Predict on test\n",
    "    preds_test_log = model.predict(test_pool)\n",
    "    preds_test_lin = np.expm1(preds_test_log)\n",
    "\n",
    "    test_preds_log += preds_test_log\n",
    "    test_preds_lin += preds_test_lin\n",
    "\n",
    "    # OOF predictions for this fold\n",
    "    oof_preds[idx_val] = np.expm1(model.predict(val_pool))\n",
    "\n",
    "# Average predictions\n",
    "test_preds_log = np.expm1(test_preds_log / cv.get_n_splits())  # average in log space\n",
    "test_preds_lin = test_preds_lin / cv.get_n_splits()            # average in linear space\n",
    "\n",
    "# Compute OOF RMSLE\n",
    "rmsle_oof = np.sqrt(mean_squared_error(np.log1p(y_train), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle_oof:.5f}\")\n",
    "\n",
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_new_age.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_new_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAtboost woth the addiitonal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_age_cat.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_age_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[categorical_cols].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
