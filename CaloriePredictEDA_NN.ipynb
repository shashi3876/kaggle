{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj0O63RU53jX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "THis notebook contains he final notebook submission to the Kaggle competion predcit Calories challenge. I will start by first havoing code to the best possible solution based on the public leaderboard) and then explore other options. EDA and other stuff have been removed from this notebook for readability.\n",
    "The code is inspired by this notebook.\n",
    "\n",
    "https://www.kaggle.com/code/tmtngtrng/neural-network-and-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vDPkI88a0LAu"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zFS_dZcX0PWt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n",
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)\n",
    "\n",
    "# Squares of features\n",
    "train['dur_2']=train['Duration']*train['Duration']\n",
    "test['dur_2']=test['Duration']*test['Duration']\n",
    "\n",
    "train['hr_2']=train['Heart_Rate']*train['Heart_Rate']\n",
    "test['hr_2']=test['Heart_Rate']*test['Heart_Rate']\n",
    "\n",
    "train['height_2']=train['Height']*train['Height']\n",
    "test['height_2']=test['Height']*test['Height']\n",
    "\n",
    "train['weight_2']=train['Weight']*train['Weight']\n",
    "test['weight_2']=test['Weight']*test['Weight']\n",
    "\n",
    "# Square root of Duration\n",
    "train['dur_sqrt'] = train['Duration'] ** 0.5\n",
    "test['dur_sqrt'] = test['Duration'] ** 0.5\n",
    "\n",
    "train['hr_sqrt'] = train['Heart_Rate'] ** 0.5\n",
    "test['hr_sqrt'] = test['Heart_Rate'] ** 0.5\n",
    "\n",
    "train['weight_sqrt'] = train['Weight'] ** 0.5\n",
    "test['weight_sqrt'] = test['Weight'] ** 0.5\n",
    "\n",
    "train['height_sqrt'] = train['Height'] ** 0.5\n",
    "test['height_sqrt'] = test['Height'] ** 0.5\n",
    "\n",
    "train['Intensity'] = train['Heart_Rate'] / train['Duration']\n",
    "test['Intensity'] = test['Heart_Rate'] / test['Duration']\n",
    "\n",
    "# Create binary indicators\n",
    "train['is_male'] = (train['Sex'].str.lower() == 'male').astype(int)\n",
    "train['is_female'] = (train['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "test['is_male'] = (test['Sex'].str.lower() == 'male').astype(int)\n",
    "test['is_female'] = (test['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "# Numerical columns to interact with sex\n",
    "num_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height', 'Body_Temp','bmi','Intensity','dur_body_heart']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in ['Weight', 'Height', 'Duration', 'Heart_Rate', 'Body_Temp']:\n",
    "    train[f'{col}_log'] = np.log1p(train[col])\n",
    "    test[f'{col}_log'] = np.log1p(test[col])\n",
    "\n",
    "train['Weight_Height_ratio'] = train['Weight'] / train['Height']\n",
    "test['Weight_Height_ratio'] = test['Weight'] / test['Height']\n",
    "\n",
    "train['HeartRate_BodyTemp_ratio'] = train['Heart_Rate'] / train['Body_Temp']\n",
    "test['HeartRate_BodyTemp_ratio'] = test['Heart_Rate'] / test['Body_Temp']\n",
    "\n",
    "\n",
    "train['effort_per_kg'] = train['Duration'] * train['Heart_Rate'] / train['Weight']\n",
    "test['effort_per_kg'] = test['Duration'] * test['Heart_Rate'] / test['Weight']\n",
    "\n",
    "\n",
    "train['Age_HeartRate'] = train['Age'] * train['Heart_Rate']\n",
    "test['Age_HeartRate'] = test['Age'] * test['Heart_Rate']\n",
    "\n",
    "train['Temp_Height'] = train['Body_Temp'] * train['Height']\n",
    "test['Temp_Height'] = test['Body_Temp'] * test['Height']\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "poly_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height']\n",
    "for col1, col2 in combinations(poly_cols, 2):\n",
    "    train[f'{col1}_x_{col2}'] = train[col1] * train[col2]\n",
    "    test[f'{col1}_x_{col2}'] = test[col1] * test[col2]\n",
    "\n",
    "\n",
    "for col in poly_cols:\n",
    "    col_mean = train[col].mean()  # Calculate mean from training data\n",
    "    train[f'{col}_mean_diff'] = train[col] - col_mean\n",
    "    test[f'{col}_mean_diff'] = test[col] - col_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate',\n",
       "       'Body_Temp', 'Calories', 'bmi', 'dur_body_heart', 'BMR', 'dur_2',\n",
       "       'hr_2', 'height_2', 'weight_2', 'dur_sqrt', 'hr_sqrt', 'weight_sqrt',\n",
       "       'height_sqrt', 'Intensity', 'is_male', 'is_female', 'Age_Male',\n",
       "       'Age_Female', 'Duration_Male', 'Duration_Female', 'Heart_Rate_Male',\n",
       "       'Heart_Rate_Female', 'Weight_Male', 'Weight_Female', 'Height_Male',\n",
       "       'Height_Female', 'Body_Temp_Male', 'Body_Temp_Female', 'bmi_Male',\n",
       "       'bmi_Female', 'Intensity_Male', 'Intensity_Female',\n",
       "       'dur_body_heart_Male', 'dur_body_heart_Female', 'Weight_log',\n",
       "       'Height_log', 'Duration_log', 'Heart_Rate_log', 'Body_Temp_log',\n",
       "       'Weight_Height_ratio', 'HeartRate_BodyTemp_ratio', 'effort_per_kg',\n",
       "       'Age_HeartRate', 'Temp_Height', 'Age_x_Duration', 'Age_x_Heart_Rate',\n",
       "       'Age_x_Weight', 'Age_x_Height', 'Duration_x_Heart_Rate',\n",
       "       'Duration_x_Weight', 'Duration_x_Height', 'Heart_Rate_x_Weight',\n",
       "       'Heart_Rate_x_Height', 'Weight_x_Height'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_loss(y_pred, y_true):\n",
    "    y_pred = torch.clamp(y_pred, min=0)\n",
    "    y_true = torch.clamp(y_true, min=0)\n",
    "    return torch.sqrt(F.mse_loss(torch.log1p(y_pred), torch.log1p(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalorieNet(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.1, use_residual=True):\n",
    "            super(CalorieNet, self).__init__()\n",
    "            \n",
    "            self.use_residual = use_residual\n",
    "            \n",
    "            self.input_norm = nn.BatchNorm1d(input_dim)\n",
    "            self.backbone = nn.ModuleList([\n",
    "                self._make_block(input_dim, 512, dropout),\n",
    "                self._make_block(512, 256, dropout),\n",
    "                self._make_block(256, 128, dropout),\n",
    "                self._make_block(128, 64, dropout),\n",
    "            ])\n",
    "            \n",
    "            self.output_head = nn.Sequential(\n",
    "                nn.Linear(64, 32),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout * 0.5),  \n",
    "                nn.Linear(32, 1),\n",
    "                nn.Softplus()\n",
    "            )\n",
    "            \n",
    "\n",
    "            self._initialize_weights()\n",
    "        \n",
    "    def _make_block(self, in_features, out_features, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_norm(x)\n",
    "        for block in self.backbone:\n",
    "            if self.use_residual and x.shape[1] == block[0].in_features and x.shape[1] == block[0].out_features:\n",
    "                x = x + block(x)\n",
    "            else:\n",
    "                x = block(x)\n",
    "        x = self.output_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'Calories']\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "\n",
    "\n",
    "def get_max_min(series: pd.Series) -> list:\n",
    "    return [series.max(), series.min()]\n",
    "\n",
    "def max_min_scalse(series: pd.Series) -> pd.Series:\n",
    "    max_min = get_max_min(series)\n",
    "    return series.apply(lambda x: (x - max_min[1]) / (max_min[0] - max_min[1]))\n",
    "\n",
    "for col in X.columns:\n",
    "    if col != 'Sex':\n",
    "        X[col] = max_min_scalse(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 512\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 46)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model (RMSLE: 0.059356, improved by 1.56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 141.99it/s, loss=0.0652, lr=0.00207, rmsle=0.0652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/500\n",
      "Train Loss: 0.063547, Train RMSLE: 0.063547\n",
      "Val RMSLE: 0.061244, LR: 0.00206721\n",
      "No improvement for 1/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/500: 100%|██████████████████████████████████████| 1172/1172 [00:08<00:00, 142.53it/s, loss=0.069, lr=0.00215, rmsle=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/500\n",
      "Train Loss: 0.063741, Train RMSLE: 0.063741\n",
      "Val RMSLE: 0.062841, LR: 0.00214701\n",
      "No improvement for 2/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/500: 100%|████████████████████████████████████| 1172/1172 [00:10<00:00, 113.24it/s, loss=0.0772, lr=0.00222, rmsle=0.0772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/500\n",
      "Train Loss: 0.063392, Train RMSLE: 0.063392\n",
      "Val RMSLE: 0.060129, LR: 0.00222484\n",
      "No improvement for 3/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/500: 100%|█████████████████████████████████████| 1172/1172 [00:08<00:00, 142.12it/s, loss=0.0555, lr=0.0023, rmsle=0.0555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/500\n",
      "Train Loss: 0.063387, Train RMSLE: 0.063387\n",
      "Val RMSLE: 0.060953, LR: 0.00230041\n",
      "No improvement for 4/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 143.91it/s, loss=0.0546, lr=0.00237, rmsle=0.0546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/500\n",
      "Train Loss: 0.062788, Train RMSLE: 0.062788\n",
      "Val RMSLE: 0.062607, LR: 0.00237341\n",
      "No improvement for 5/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 136.01it/s, loss=0.0732, lr=0.00244, rmsle=0.0732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/500\n",
      "Train Loss: 0.063039, Train RMSLE: 0.063039\n",
      "Val RMSLE: 0.061241, LR: 0.00244355\n",
      "No improvement for 6/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 137.46it/s, loss=0.0583, lr=0.00251, rmsle=0.0583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/500\n",
      "Train Loss: 0.062523, Train RMSLE: 0.062523\n",
      "Val RMSLE: 0.065933, LR: 0.00251056\n",
      "No improvement for 7/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 142.83it/s, loss=0.0839, lr=0.00257, rmsle=0.0839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/500\n",
      "Train Loss: 0.062818, Train RMSLE: 0.062818\n",
      "Val RMSLE: 0.061821, LR: 0.00257418\n",
      "No improvement for 8/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/500: 100%|████████████████████████████████████| 1172/1172 [00:07<00:00, 147.69it/s, loss=0.0525, lr=0.00263, rmsle=0.0525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/500\n",
      "Train Loss: 0.062614, Train RMSLE: 0.062614\n",
      "Val RMSLE: 0.061236, LR: 0.00263415\n",
      "No improvement for 9/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/500: 100%|████████████████████████████████████| 1172/1172 [00:09<00:00, 127.30it/s, loss=0.0734, lr=0.00269, rmsle=0.0734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/500\n",
      "Train Loss: 0.062880, Train RMSLE: 0.062880\n",
      "Val RMSLE: 0.064951, LR: 0.00269023\n",
      "No improvement for 10/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/500: 100%|████████████████████████████████████| 1172/1172 [00:07<00:00, 147.53it/s, loss=0.0602, lr=0.00274, rmsle=0.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/500\n",
      "Train Loss: 0.062952, Train RMSLE: 0.062952\n",
      "Val RMSLE: 0.059902, LR: 0.00274221\n",
      "No improvement for 11/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 138.30it/s, loss=0.0916, lr=0.00279, rmsle=0.0916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/500\n",
      "Train Loss: 0.062753, Train RMSLE: 0.062753\n",
      "Val RMSLE: 0.061598, LR: 0.00278987\n",
      "No improvement for 12/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 143.19it/s, loss=0.0869, lr=0.00283, rmsle=0.0869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/500\n",
      "Train Loss: 0.062980, Train RMSLE: 0.062980\n",
      "Val RMSLE: 0.063420, LR: 0.00283304\n",
      "No improvement for 13/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 145.55it/s, loss=0.0706, lr=0.00287, rmsle=0.0706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/500\n",
      "Train Loss: 0.062449, Train RMSLE: 0.062449\n",
      "Val RMSLE: 0.060716, LR: 0.00287154\n",
      "No improvement for 14/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/500: 100%|████████████████████████████████████| 1172/1172 [00:07<00:00, 150.09it/s, loss=0.0595, lr=0.00291, rmsle=0.0595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/500\n",
      "Train Loss: 0.062315, Train RMSLE: 0.062315\n",
      "Val RMSLE: 0.059711, LR: 0.00290522\n",
      "No improvement for 15/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 138.54it/s, loss=0.0607, lr=0.00293, rmsle=0.0607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/500\n",
      "Train Loss: 0.062115, Train RMSLE: 0.062115\n",
      "Val RMSLE: 0.061511, LR: 0.00293395\n",
      "No improvement for 16/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/500: 100%|████████████████████████████████████| 1172/1172 [00:08<00:00, 143.32it/s, loss=0.0563, lr=0.00296, rmsle=0.0563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/500\n",
      "Train Loss: 0.062347, Train RMSLE: 0.062347\n",
      "Val RMSLE: 0.060825, LR: 0.00295760\n",
      "No improvement for 17/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/500: 100%|████████████████████████████████████| 1172/1172 [00:07<00:00, 154.54it/s, loss=0.0704, lr=0.00298, rmsle=0.0704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/500\n",
      "Train Loss: 0.062227, Train RMSLE: 0.062227\n",
      "Val RMSLE: 0.060491, LR: 0.00297610\n",
      "No improvement for 18/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/500: 100%|████████████████████████████████████| 1172/1172 [00:07<00:00, 153.54it/s, loss=0.0865, lr=0.00299, rmsle=0.0865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/500\n",
      "Train Loss: 0.062273, Train RMSLE: 0.062273\n",
      "Val RMSLE: 0.060239, LR: 0.00298936\n",
      "No improvement for 19/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/500: 100%|██████████████████████████████████████| 1172/1172 [00:07<00:00, 147.37it/s, loss=0.0524, lr=0.003, rmsle=0.0524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/500\n",
      "Train Loss: 0.062331, Train RMSLE: 0.062331\n",
      "Val RMSLE: 0.062057, LR: 0.00299734\n",
      "No improvement for 20/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/500: 100%|████████████████████████████████████████| 1172/1172 [00:07<00:00, 152.24it/s, loss=0.102, lr=0.003, rmsle=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/500\n",
      "Train Loss: 0.061916, Train RMSLE: 0.061916\n",
      "Val RMSLE: 0.060751, LR: 0.00300000\n",
      "No improvement for 21/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/500: 100%|██████████████████████████████████████| 1172/1172 [00:08<00:00, 144.49it/s, loss=0.0649, lr=0.003, rmsle=0.0649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/500\n",
      "Train Loss: 0.062070, Train RMSLE: 0.062070\n",
      "Val RMSLE: 0.060371, LR: 0.00299996\n",
      "No improvement for 22/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/500: 100%|██████████████████████████████████████| 1172/1172 [00:09<00:00, 125.87it/s, loss=0.0582, lr=0.003, rmsle=0.0582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52/500\n",
      "Train Loss: 0.061938, Train RMSLE: 0.061938\n",
      "Val RMSLE: 0.059994, LR: 0.00299985\n",
      "No improvement for 23/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/500: 100%|██████████████████████████████████████| 1172/1172 [00:08<00:00, 145.01it/s, loss=0.0493, lr=0.003, rmsle=0.0493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53/500\n",
      "Train Loss: 0.061919, Train RMSLE: 0.061919\n",
      "Val RMSLE: 0.059985, LR: 0.00299967\n",
      "No improvement for 24/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/500: 100%|██████████████████████████████████████| 1172/1172 [00:07<00:00, 156.57it/s, loss=0.0567, lr=0.003, rmsle=0.0567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54/500\n",
      "Train Loss: 0.061900, Train RMSLE: 0.061900\n",
      "Val RMSLE: 0.060230, LR: 0.00299942\n",
      "No improvement for 25/25 epochs\n",
      "Early stopping triggered after 25 epochs without improvement\n",
      "Best RMSLE: 0.059356\n"
     ]
    }
   ],
   "source": [
    "model = CalorieNet(\n",
    "        input_dim=46,  \n",
    "        dropout=0.00,\n",
    "        use_residual=True\n",
    "    ).to(device)\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'BatchNorm']\n",
    "decay_params = []\n",
    "no_decay_params = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    if any(nd in name for nd in no_decay):\n",
    "        no_decay_params.append(param)\n",
    "    else:\n",
    "        decay_params.append(param)\n",
    "        \n",
    "optimizer_params = [\n",
    "    {'params': decay_params, 'weight_decay': 5e-4}, \n",
    "    {'params': no_decay_params, 'weight_decay': 0.0}\n",
    "]\n",
    "loss_fn_rmsle = rmsle_loss\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 25\n",
    "counter = 0\n",
    "scaler = torch.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "max_epochs = 500\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_params,\n",
    "    lr=3e-4, \n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "total_steps = max_epochs * len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-3,\n",
    "    epochs=max_epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,  \n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=100.0\n",
    ")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_rmsle = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "    for batch_X, batch_y in progress_bar:\n",
    "        batch_X = batch_X.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        if scaler:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                output = model(batch_X)\n",
    "                loss = rmsle_loss(output, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            output = model(batch_X)\n",
    "            loss = rmsle_loss(output, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()  \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            rmsle = loss_fn_rmsle(output, batch_y)\n",
    "            total_train_rmsle += rmsle.item()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            loss=loss.item(),\n",
    "            rmsle=rmsle.item(),\n",
    "            lr=scheduler.get_last_lr()[0]\n",
    "        )\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_rmsle = total_train_rmsle / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device, non_blocking=True)\n",
    "            batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(batch_X)\n",
    "            val_loss = loss_fn_rmsle(output, batch_y)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{max_epochs}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.6f}, Train RMSLE: {avg_train_rmsle:.6f}\")\n",
    "    print(f\"Val RMSLE: {avg_val_loss:.6f}, LR: {scheduler.get_last_lr()[0]:.8f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        improvement = (best_val_loss - avg_val_loss) / best_val_loss * 100\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"calorie_model_best.pt\")\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Saved best model (RMSLE: {best_val_loss:.6f}, improved by {improvement:.2f}%)\")\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement for {counter}/{patience} epochs\")\n",
    "        if counter >= patience:\n",
    "            \n",
    "            print(f\"Early stopping triggered after {patience} epochs without improvement\")\n",
    "            print(f\"Best RMSLE: {best_val_loss:.6f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do predcitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalorieNet(\n",
       "  (input_norm): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (backbone): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=46, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (4): Softplus(beta=1.0, threshold=20.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CalorieNet(\n",
    "    input_dim=46,  \n",
    "    dropout=0.00,\n",
    "    use_residual=True\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"calorie_model_best.pt\"))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Drop the 'id' column to get model inputs\n",
    "X_test = test.drop(columns=['id'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if col != 'Sex':\n",
    "        X_test[col] = max_min_scalse(X_test[col])\n",
    "\n",
    "\n",
    "# Convert to tensor\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(X_test_tensor, batch_size=128, shuffle=False)\n",
    "\n",
    "# Load model\n",
    "model = CalorieNet(\n",
    "    input_dim=59,  \n",
    "    dropout=0.00,\n",
    "    use_residual=True\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"calorie_model_best.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X in test_loader:\n",
    "        batch_X = batch_X.to(device, non_blocking=True)\n",
    "        preds = model(batch_X)\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "# Combine and convert predictions\n",
    "final_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "\n",
    "# Apply inverse log transform if necessary\n",
    "final_preds = np.expm1(final_preds)\n",
    "\n",
    "# Save predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'].values,\n",
    "    'Calories': final_preds.flatten()\n",
    "})\n",
    "submission_df.to_csv('calorie_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure test uses the same feature columns as X\n",
    "X_test_new = test[X.columns]  # Ensure same order and columns\n",
    "\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if col != 'Sex':\n",
    "        X_test_new[col] = max_min_scalse(X_test_new[col])\n",
    "        \n",
    "# Convert to tensor\n",
    "X_test_tensor = torch.tensor(X_test_new.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# DataLoader\n",
    "test_loader = DataLoader(X_test_tensor, batch_size=512, shuffle=False)\n",
    "\n",
    "# Recreate and load the trained model\n",
    "model = CalorieNet(\n",
    "    input_dim=X.shape[1],  # same as train\n",
    "    dropout=0.00,\n",
    "    use_residual=True\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"calorie_model_best.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X in test_loader:\n",
    "        batch_X = batch_X.to(device, non_blocking=True)\n",
    "        preds = model(batch_X)\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "# Combine predictions\n",
    "final_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "\n",
    "# Apply inverse log transform (since you trained on log1p)\n",
    "final_preds = np.expm1(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)  # Remove negative/infinite values\n",
    "\n",
    "# Save to CSV\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'].values,\n",
    "    'Calories': final_preds.flatten()\n",
    "})\n",
    "submission_df.to_csv('calorie_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Min-Max scaling (same as in training)\n",
    "def get_max_min(series: pd.Series) -> list:\n",
    "    return [series.max(), series.min()]\n",
    "\n",
    "def max_min_scale(series: pd.Series) -> pd.Series:\n",
    "    max_min = get_max_min(series)\n",
    "    return series.apply(lambda x: (x - max_min[1]) / (max_min[0] - max_min[1]))\n",
    "\n",
    "for col in test.columns:\n",
    "    if col not in ['id', 'Sex']:\n",
    "        test[col] = max_min_scale(test[col])\n",
    "\n",
    "# --- Tensor Conversion ---\n",
    "X_final_test = test.drop(columns=['id'])\n",
    "X_final_tensor = torch.tensor(X_final_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# --- Model Loading ---\n",
    "model = CalorieNet(\n",
    "    input_dim=46,  \n",
    "    dropout=0.00,\n",
    "    use_residual=True\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"calorie_model_best.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# --- Predictions ---\n",
    "with torch.no_grad():\n",
    "    preds = model(X_final_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# --- Save Results ---\n",
    "test['Calories'] = preds\n",
    "test[['id', 'Calories']].to_csv('calorie_predictions_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 47)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
