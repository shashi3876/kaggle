{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj0O63RU53jX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "THis notebook contains he final notebook submission to the Kaggle competion predcit Calories challenge. I will start by first havoing code to the best possible solution based on the public leaderboard) and then explore other options. EDA and other stuff have been removed from this notebook for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vDPkI88a0LAu"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zFS_dZcX0PWt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('PredictCalorie/train.csv')\n",
    "test = pd.read_csv('PredictCalorie/test.csv')\n",
    "sample = pd.read_csv('PredictCalorie/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain['Duration_2'] = train['Duration']\\ntest['Duration_2'] = test['Duration']\\n\\ntrain['Age_2'] = train['Age']\\ntest['Age_2'] = test['Age']\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['bmi']=train['Weight']/(train['Height']*train['Height'])*100*100\n",
    "test['bmi']=test['Weight']/(test['Height']*test['Height'])*100*100\n",
    "\n",
    "train['dur_body_heart']=train['Duration']*train['Heart_Rate']*train['Body_Temp']\n",
    "test['dur_body_heart']=test['Duration']*test['Heart_Rate']*test['Body_Temp']\n",
    "\n",
    "def calculate_bmr(row):\n",
    "    if row['Sex'].lower() == 'male':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] + 5\n",
    "    elif row['Sex'].lower() == 'female':\n",
    "        return 10 * row['Weight'] + 6.25 * row['Height'] - 5 * row['Age'] - 161\n",
    "    else:\n",
    "        return np.nan  # handle unknown or missing Sex\n",
    "\n",
    "train['BMR'] = train.apply(calculate_bmr, axis=1)\n",
    "test['BMR'] = test.apply(calculate_bmr, axis=1)\n",
    "\n",
    "# Squares of features\n",
    "train['dur_2']=train['Duration']*train['Duration']\n",
    "test['dur_2']=test['Duration']*test['Duration']\n",
    "\n",
    "train['hr_2']=train['Heart_Rate']*train['Heart_Rate']\n",
    "test['hr_2']=test['Heart_Rate']*test['Heart_Rate']\n",
    "\n",
    "train['height_2']=train['Height']*train['Height']\n",
    "test['height_2']=test['Height']*test['Height']\n",
    "\n",
    "train['weight_2']=train['Weight']*train['Weight']\n",
    "test['weight_2']=test['Weight']*test['Weight']\n",
    "\n",
    "# Square root of Duration\n",
    "train['dur_sqrt'] = train['Duration'] ** 0.5\n",
    "test['dur_sqrt'] = test['Duration'] ** 0.5\n",
    "\n",
    "train['hr_sqrt'] = train['Heart_Rate'] ** 0.5\n",
    "test['hr_sqrt'] = test['Heart_Rate'] ** 0.5\n",
    "\n",
    "train['weight_sqrt'] = train['Weight'] ** 0.5\n",
    "test['weight_sqrt'] = test['Weight'] ** 0.5\n",
    "\n",
    "train['height_sqrt'] = train['Height'] ** 0.5\n",
    "test['height_sqrt'] = test['Height'] ** 0.5\n",
    "\n",
    "train['Intensity'] = train['Heart_Rate'] / train['Duration']\n",
    "test['Intensity'] = test['Heart_Rate'] / test['Duration']\n",
    "\n",
    "# Create binary indicators\n",
    "train['is_male'] = (train['Sex'].str.lower() == 'male').astype(int)\n",
    "train['is_female'] = (train['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "test['is_male'] = (test['Sex'].str.lower() == 'male').astype(int)\n",
    "test['is_female'] = (test['Sex'].str.lower() == 'female').astype(int)\n",
    "\n",
    "# Numerical columns to interact with sex\n",
    "num_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height', 'Body_Temp','bmi','Intensity','dur_body_heart']\n",
    "\n",
    "# Create interaction features\n",
    "for col in num_cols:\n",
    "    train[f'{col}_Male'] = train[col] * train['is_male']\n",
    "    train[f'{col}_Female'] = train[col] * train['is_female']\n",
    "\n",
    "    test[f'{col}_Male'] = test[col] * test['is_male']\n",
    "    test[f'{col}_Female'] = test[col] * test['is_female']\n",
    "\n",
    "\n",
    "for col in ['Weight', 'Height', 'Duration', 'Heart_Rate', 'Body_Temp']:\n",
    "    train[f'{col}_log'] = np.log1p(train[col])\n",
    "    test[f'{col}_log'] = np.log1p(test[col])\n",
    "\n",
    "train['Weight_Height_ratio'] = train['Weight'] / train['Height']\n",
    "test['Weight_Height_ratio'] = test['Weight'] / test['Height']\n",
    "\n",
    "train['HeartRate_BodyTemp_ratio'] = train['Heart_Rate'] / train['Body_Temp']\n",
    "test['HeartRate_BodyTemp_ratio'] = test['Heart_Rate'] / test['Body_Temp']\n",
    "\n",
    "\n",
    "train['effort_per_kg'] = train['Duration'] * train['Heart_Rate'] / train['Weight']\n",
    "test['effort_per_kg'] = test['Duration'] * test['Heart_Rate'] / test['Weight']\n",
    "\n",
    "\n",
    "train['Age_HeartRate'] = train['Age'] * train['Heart_Rate']\n",
    "test['Age_HeartRate'] = test['Age'] * test['Heart_Rate']\n",
    "\n",
    "train['Temp_Height'] = train['Body_Temp'] * train['Height']\n",
    "test['Temp_Height'] = test['Body_Temp'] * test['Height']\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "poly_cols = ['Age', 'Duration', 'Heart_Rate', 'Weight', 'Height']\n",
    "for col1, col2 in combinations(poly_cols, 2):\n",
    "    train[f'{col1}_x_{col2}'] = train[col1] * train[col2]\n",
    "    test[f'{col1}_x_{col2}'] = test[col1] * test[col2]\n",
    "'''\n",
    "train['Duration_2'] = train['Duration']\n",
    "test['Duration_2'] = test['Duration']\n",
    "\n",
    "train['Age_2'] = train['Age']\n",
    "test['Age_2'] = test['Age']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate',\n",
       "       'Body_Temp', 'Calories', 'bmi', 'dur_body_heart', 'BMR', 'dur_2',\n",
       "       'hr_2', 'height_2', 'weight_2', 'dur_sqrt', 'hr_sqrt', 'weight_sqrt',\n",
       "       'height_sqrt', 'Intensity', 'is_male', 'is_female', 'Age_Male',\n",
       "       'Age_Female', 'Duration_Male', 'Duration_Female', 'Heart_Rate_Male',\n",
       "       'Heart_Rate_Female', 'Weight_Male', 'Weight_Female', 'Height_Male',\n",
       "       'Height_Female', 'Body_Temp_Male', 'Body_Temp_Female', 'bmi_Male',\n",
       "       'bmi_Female', 'Intensity_Male', 'Intensity_Female',\n",
       "       'dur_body_heart_Male', 'dur_body_heart_Female', 'Weight_log',\n",
       "       'Height_log', 'Duration_log', 'Heart_Rate_log', 'Body_Temp_log',\n",
       "       'Weight_Height_ratio', 'HeartRate_BodyTemp_ratio', 'effort_per_kg',\n",
       "       'Age_HeartRate', 'Temp_Height', 'Age_x_Duration', 'Age_x_Heart_Rate',\n",
       "       'Age_x_Weight', 'Age_x_Height', 'Duration_x_Heart_Rate',\n",
       "       'Duration_x_Weight', 'Duration_x_Height', 'Heart_Rate_x_Weight',\n",
       "       'Heart_Rate_x_Height', 'Weight_x_Height'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_loss(y_pred, y_true):\n",
    "    y_pred = torch.clamp(y_pred, min=0)\n",
    "    y_true = torch.clamp(y_true, min=0)\n",
    "    return torch.sqrt(F.mse_loss(torch.log1p(y_pred), torch.log1p(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalorieNet(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.1, use_residual=True):\n",
    "            super(CalorieNet, self).__init__()\n",
    "            \n",
    "            self.use_residual = use_residual\n",
    "            \n",
    "            self.input_norm = nn.BatchNorm1d(input_dim)\n",
    "            self.backbone = nn.ModuleList([\n",
    "                self._make_block(input_dim, 512, dropout),\n",
    "                self._make_block(512, 256, dropout),\n",
    "                self._make_block(256, 128, dropout),\n",
    "                self._make_block(128, 64, dropout),\n",
    "            ])\n",
    "            \n",
    "            self.output_head = nn.Sequential(\n",
    "                nn.Linear(64, 32),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout * 0.5),  \n",
    "                nn.Linear(32, 1),\n",
    "                nn.Softplus()\n",
    "            )\n",
    "            \n",
    "\n",
    "            self._initialize_weights()\n",
    "        \n",
    "    def _make_block(self, in_features, out_features, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_norm(x)\n",
    "        for block in self.backbone:\n",
    "            if self.use_residual and x.shape[1] == block[0].in_features and x.shape[1] == block[0].out_features:\n",
    "                x = x + block(x)\n",
    "            else:\n",
    "                x = block(x)\n",
    "        x = self.output_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'Calories']\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "\n",
    "\n",
    "def get_max_min(series: pd.Series) -> list:\n",
    "    return [series.max(), series.min()]\n",
    "\n",
    "def max_min_scalse(series: pd.Series) -> pd.Series:\n",
    "    max_min = get_max_min(series)\n",
    "    return series.apply(lambda x: (x - max_min[1]) / (max_min[0] - max_min[1]))\n",
    "\n",
    "for col in X.columns:\n",
    "    if col != 'Sex':\n",
    "        X[col] = max_min_scalse(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 512\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 59)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model (RMSLE: 0.059300, improved by 0.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/500: 100%|██████████████████████████████████████| 1172/1172 [00:09<00:00, 125.55it/s, loss=0.0668, lr=0.003, rmsle=0.0668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54/500\n",
      "Train Loss: 0.062202, Train RMSLE: 0.062202\n",
      "Val RMSLE: 0.060751, LR: 0.00299942\n",
      "No improvement for 1/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/500: 100%|██████████████████████████████████████| 1172/1172 [00:08<00:00, 138.14it/s, loss=0.0626, lr=0.003, rmsle=0.0626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55/500\n",
      "Train Loss: 0.061876, Train RMSLE: 0.061876\n",
      "Val RMSLE: 0.059743, LR: 0.00299909\n",
      "No improvement for 2/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/500: 100%|██████████████████████████████████████| 1172/1172 [00:05<00:00, 201.89it/s, loss=0.0545, lr=0.003, rmsle=0.0545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56/500\n",
      "Train Loss: 0.062103, Train RMSLE: 0.062103\n",
      "Val RMSLE: 0.060485, LR: 0.00299869\n",
      "No improvement for 3/25 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/500:  47%|██████████████████▎                    | 549/1172 [00:03<00:02, 211.28it/s, loss=0.0861, lr=0.003, rmsle=0.0861]"
     ]
    }
   ],
   "source": [
    "model = CalorieNet(\n",
    "        input_dim=59,  \n",
    "        dropout=0.00,\n",
    "        use_residual=True\n",
    "    ).to(device)\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'BatchNorm']\n",
    "decay_params = []\n",
    "no_decay_params = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    if any(nd in name for nd in no_decay):\n",
    "        no_decay_params.append(param)\n",
    "    else:\n",
    "        decay_params.append(param)\n",
    "        \n",
    "optimizer_params = [\n",
    "    {'params': decay_params, 'weight_decay': 5e-4}, \n",
    "    {'params': no_decay_params, 'weight_decay': 0.0}\n",
    "]\n",
    "loss_fn_rmsle = rmsle_loss\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 25\n",
    "counter = 0\n",
    "scaler = torch.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "max_epochs = 500\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_params,\n",
    "    lr=3e-4, \n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "total_steps = max_epochs * len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-3,\n",
    "    epochs=max_epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,  \n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=100.0\n",
    ")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_rmsle = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "    for batch_X, batch_y in progress_bar:\n",
    "        batch_X = batch_X.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "        if scaler:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                output = model(batch_X)\n",
    "                loss = rmsle_loss(output, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            output = model(batch_X)\n",
    "            loss = rmsle_loss(output, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()  \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            rmsle = loss_fn_rmsle(output, batch_y)\n",
    "            total_train_rmsle += rmsle.item()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            loss=loss.item(),\n",
    "            rmsle=rmsle.item(),\n",
    "            lr=scheduler.get_last_lr()[0]\n",
    "        )\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_rmsle = total_train_rmsle / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device, non_blocking=True)\n",
    "            batch_y = batch_y.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(batch_X)\n",
    "            val_loss = loss_fn_rmsle(output, batch_y)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{max_epochs}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.6f}, Train RMSLE: {avg_train_rmsle:.6f}\")\n",
    "    print(f\"Val RMSLE: {avg_val_loss:.6f}, LR: {scheduler.get_last_lr()[0]:.8f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        improvement = (best_val_loss - avg_val_loss) / best_val_loss * 100\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"calorie_model_best.pt\")\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Saved best model (RMSLE: {best_val_loss:.6f}, improved by {improvement:.2f}%)\")\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement for {counter}/{patience} epochs\")\n",
    "        if counter >= patience:\n",
    "            \n",
    "            print(f\"Early stopping triggered after {patience} epochs without improvement\")\n",
    "            print(f\"Best RMSLE: {best_val_loss:.6f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "cat_features = ['Sex','Duration','Age']\n",
    "categorical_cols = ['Sex','Duration']#,'Age']\n",
    "# Stratification based on binned Duration\n",
    "duration_bins = pd.qcut(X['Duration'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Initialize predictions\n",
    "y_pred = np.zeros(len(test))\n",
    "oof_preds = np.zeros(len(train))  # To store OOF predictions\n",
    "\n",
    "for idx_fold, (idx_train, idx_valid) in enumerate(cv.split(X, duration_bins)):\n",
    "    print(f\"\\nFold {idx_fold + 1}\")\n",
    "    \n",
    "    X_train, y_train_fold = X.iloc[idx_train].copy(), y_log.iloc[idx_train]\n",
    "    X_valid, y_valid_fold = X.iloc[idx_valid].copy(), y_log.iloc[idx_valid]\n",
    "    X_test = test[X.columns].copy()\n",
    "\n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train_fold)\n",
    "    X_valid[categorical_cols] = encoder.transform(X_valid[categorical_cols])\n",
    "    X_test[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Model\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=42,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_fold,\n",
    "        eval_set=[(X_valid, y_valid_fold)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Predict on test and validation sets\n",
    "    y_pred += model.predict(X_test)\n",
    "    oof_preds[idx_valid] = np.expm1(model.predict(X_valid))\n",
    "\n",
    "# Final test prediction (average)\n",
    "y_pred = np.expm1(y_pred / cv.get_n_splits()) \n",
    "\n",
    "# OOF RMSLE\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(train['Calories']), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "# Submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission_xgb = pd.DataFrame({'id': sample_submission.id, 'Calories': y_pred})\n",
    "submission_xgb.to_csv('submission_xgb_category.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drop_cols = ['id', 'Calories']\n",
    "X = train.drop(columns=drop_cols)\n",
    "y = train['Calories']\n",
    "# Setup\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = test.drop(columns=['id'])\n",
    "categorical_cols = ['Sex']#,'Duration','Age']\n",
    "\n",
    "# Stratify on Duration bins\n",
    "duration_bins = pd.qcut(train['Duration'], q=10, labels=False)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize prediction arrays\n",
    "test_preds_log = np.zeros(len(test))       # accumulate raw predictions (log)\n",
    "test_preds_lin = np.zeros(len(test))       # accumulate converted predictions\n",
    "oof_preds = np.zeros(len(train))           # OOF predictions for validation\n",
    "\n",
    "#X_train['Duration'] = X_train['Duration'].astype(int)\n",
    "#X_test['Duration'] = X_test['Duration'].astype(int)\n",
    "# Cross-validation loop\n",
    "for fold, (idx_tr, idx_val) in enumerate(cv.split(X_train, duration_bins)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[idx_tr], X_train.iloc[idx_val]\n",
    "    y_tr, y_val = np.log1p(y_train.iloc[idx_tr]), np.log1p(y_train.iloc[idx_val])\n",
    "    \n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=categorical_cols)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "    test_pool = Pool(X_test, cat_features=categorical_cols)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        random_strength=5,\n",
    "        l2_leaf_reg=7,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        grow_policy='SymmetricTree',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    \n",
    "    # Predict on test\n",
    "    preds_test_log = model.predict(test_pool)\n",
    "    preds_test_lin = np.expm1(preds_test_log)\n",
    "\n",
    "    test_preds_log += preds_test_log\n",
    "    test_preds_lin += preds_test_lin\n",
    "\n",
    "    # OOF predictions for this fold\n",
    "    oof_preds[idx_val] = np.expm1(model.predict(val_pool))\n",
    "\n",
    "# Average predictions\n",
    "test_preds_log = np.expm1(test_preds_log / cv.get_n_splits())  # average in log space\n",
    "test_preds_lin = test_preds_lin / cv.get_n_splits()            # average in linear space\n",
    "\n",
    "# Compute OOF RMSLE\n",
    "rmsle_oof = np.sqrt(mean_squared_error(np.log1p(y_train), np.log1p(oof_preds)))\n",
    "print(f\"\\nOOF RMSLE: {rmsle_oof:.5f}\")\n",
    "\n",
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_new_age.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_new_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "test['Calories'] = test_preds_lin\n",
    "test[['id', 'Calories']].to_csv('catboost_linear_avg_age_cat.csv', index=False)\n",
    "\n",
    "test['Calories'] = test_preds_log\n",
    "test[['id', 'Calories']].to_csv('catboost_log_avg_age_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[categorical_cols].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('submission_xgb_new (1).csv')\n",
    "data2=pd.read_csv('catboost_log_avg (2).csv')\n",
    "\n",
    "data = data1.merge(data2, on='id', suffixes=('_xgb', '_cat'))\n",
    "\n",
    "\n",
    "# 1. Simple average of the two predictions\n",
    "data['Calories_avg'] = (data['Calories_xgb'] + data['Calories_cat']) / 2\n",
    "\n",
    "# 2. Log-scale average (RMSLE-style averaging)\n",
    "data['Calories_log_avg'] = np.expm1(\n",
    "    (np.log1p(data['Calories_xgb']) + np.log1p(data['Calories_cat'])) / 2\n",
    ")\n",
    "\n",
    "print(data[['id', 'Calories_xgb', 'Calories_cat', 'Calories_avg', 'Calories_log_avg']].head())\n",
    "data[['id', 'Calories_avg']].rename(columns={'Calories_avg': 'Calories'}).to_csv('submission_reg_avg_2.csv', index=False)\n",
    "\n",
    "# Save log-scale average with 'Calories' as the second column\n",
    "data[['id', 'Calories_log_avg']].rename(columns={'Calories_log_avg': 'Calories'}).to_csv('submission_log_avg_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
